#  @file
#  @author Christian Diddens <c.diddens@utwente.nl>
#  @author Duarte Rocha <d.rocha@utwente.nl>
#  
#  @section LICENSE
# 
#  pyoomph - a multi-physics finite element framework based on oomph-lib and GiNaC 
#  Copyright (C) 2021-2024  Christian Diddens & Duarte Rocha
# 
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
# 
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
# 
#  You should have received a copy of the GNU General Public License
#  along with this program.  If not, see <http://www.gnu.org/licenses/>. 
#
#  The authors may be contacted at c.diddens@utwente.nl and d.rocha@utwente.nl
#
# ========================================================================
 
import glob

import scipy.sparse

from ..expressions.generic import is_zero #type:ignore

#import pyoomph.generic
from .mpi import *
import _pyoomph
import math


import __main__

import os
import gc
from pathlib import Path

import argparse
import numpy
from ..meshes.mesh import  AnyMesh,AnySpatialMesh, MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d, ODEStorageMesh, InterfaceMesh,MeshFromTemplate,MeshFromTemplateBase,MeshTemplate
from .codegen import EquationTree,BaseEquations, FiniteElementCodeGenerator,CombinedEquations,DummyEquations, InterfaceEquations #ODEEquations
from ..solvers.generic import DefaultMatrixType, EigenSolverWhich, GenericLinearSystemSolver,GenericEigenSolver
#from ..solvers.scipy import SuperLUSerial,ScipyEigenSolver
from ..expressions.units import *
from ..expressions import get_global_symbol,cartesian,axisymmetric,axisymmetric_flipped,radialsymmetric,BaseCoordinateSystem,nondim,testfunction,evaluate_in_past,weak,OptionalCoordinateSystem
from ..solvers.load_solver_from_cmd_line import *
from ..solvers.generic import get_default_linear_solver,get_default_eigen_solver
from ..meshes.interpolator import _DefaultInterpolatorClass,ODEInterpolator 
from ..output.states import DumpFile
from ..expressions import ExpressionOrNum,ExpressionNumOrNone
from ..meshes.meshdatacache import MeshDataCacheStorage, MeshDataCacheOperatorBase, MeshDataEigenModes,MeshDataCacheEntry

from .ccompiler import BaseCCompiler,SystemCCompiler

import types 

from ..typings import *

if TYPE_CHECKING:
    from ..output.plotting import MatplotlibPlotter
    from ..meshes.remesher import RemesherBase
    from ..meshes.interpolator import BaseMeshToMeshInterpolator
    from .assembly import CustomAssemblyBase

Z2ErrorEstimator=_pyoomph.Z2ErrorEstimator

import subprocess

import signal
def breakpoint():
    os.kill(os.getpid(), signal.SIGTRAP)

#To use "with problem.custom_adapt:" statement
class _CustomAdaptWithHelper:
    def __init__(self, problem: "Problem",skip_init_call:bool=False):
        self._problem=problem
        self._skip_init_call=skip_init_call
    def __enter__(self):
        if not self._skip_init_call and  not self._problem.is_initialised():
            self._problem.initialise()
        self._problem.actions_before_adapt()
    def __exit__(self,exc_type: Optional[Type[BaseException]], exc: Optional[BaseException], traceback: Optional[types.TracebackType]):
        self._problem.actions_after_adapt()
        self._problem.before_assigning_equation_numbers(self._problem._dof_selector) #type: ignore
        num=self._problem.assign_eqn_numbers(True)
        if not self._problem.is_quiet():
            print("Number of equations: "+str(num))


class _AzimuthalStabilityInfo:
    def __init__(self):
        super(_AzimuthalStabilityInfo, self).__init__()
        self.real_contribution_name="real_contrib_azimuthal_stability"
        self.imag_contribution_name="imag_contrib_azimuthal_stability"
        self.azimuthal_param_m_name = "azimuthal_m"


#Problem with some automatic behaviour
class Problem(_pyoomph.Problem):
    """A class representing a problem in the pyoomph library.

    This class provides methods and attributes for defining and solving a problem.
    Usually, in the :py:meth:`__init__` method, you define any parameters with default settings.
    The problem itself is defined by the :py:meth:`define_problem` method, where you define the equations and the mesh(es).
    After creation of an instance, you can solve the problem by calling the :py:meth:`run` method (transient solves) or the :py:meth:`solve` method (stationary solve).
    Outputs (potentially with plots) can be generated by calling the :py:meth:`output` method.

    Attributes:
        
        additional_equations (Union[Literal[0], EquationTree]): Additional equations for the problem.
        always_take_one_newton_step (bool): Flag indicating whether to always take one Newton step.
        continuation_data_in_states (bool): Flag indicating whether to store continuation data in the states.
        default_1d_file_extension (Union[Literal["txt", "mat"], List[Literal["txt", "mat"]]]): Default file extension for 1D files.
        default_ccode_expression_mode (str): Default C code expression mode.
        default_spatial_integration_order (Union[int, None]): Default spatial integration order.
        default_timestepping_scheme (Literal["BDF2", "BDF1", "Newmark2"]): Default timestepping scheme.
        eigen_data_in_states (Union[int, bool]): Flag indicating whether to store eigen data in the states.
        eigenvector_position_scale (float): Scaling factor for eigenvector positions.
        extra_compiler_flags (List[str]): Extra compiler flags for the problem.
        ignore_command_line (bool): Flag indicating whether to ignore command line arguments.
        latex_printer (Optional[LaTeXPrinter]): LaTeX printer for the problem.
        max_residuals (float): Maximum residuals for the problem.
        plot_in_dedicated_process (bool): Flag indicating whether to plot in a dedicated process.
        remove_macro_elements_after_initial_adaption (Union[bool, Literal["auto"]]): Flag indicating whether to remove macro elements after initial adaption.
        scaling (Dict[str, Union[str, ExpressionOrNum]]): Dictionary of scaling factors.
        states_compression_level (Union[int, None]): Compression level for the states.
        timestepper (MultiTimeStepper): Timestepper for the problem.
        write_states (bool): Flag indicating whether to write states.

    """
    def __init__(self):
        """
        Initialise the problem object. After calling ``super().__init__()``, you should set the default parameters for the problem. Afterwards, the user can change them before solving the problem. 
        """
        super(Problem, self).__init__()
        self._initialised:bool=False
        self._during_initialization:bool=False

        import pyoomph
        self.set_c_compiler(pyoomph.get_default_c_compiler())

        if hasattr(__main__,"__file__"):
            scriptfile=os.path.splitext(__main__.__file__)[0]
        else:
            scriptfile="_pyoomph_output_.py"
        #self._outdir=os.path.join(os.path.dirname(scriptfile),os.path.basename(scriptfile))
        self._outdir:str = os.path.basename(scriptfile)

        self._bulk_element_code_counter:int=0

        self._first_step:bool=True
        self._suppress_code_writing:bool=False
        self._suppress_compilation:bool=False
        self._debug_largest_residual:int=0
        self.ignore_command_line:bool=False

        self._ccode_dir:str="_ccode"
        self._dof_selector:Union[_DofSelector,None]=None # The desired selected dofs
        self._dof_selector_used:Union[_DofSelector,None,Literal["INVALID"]]=None


        self._use_first_order_timestepper:bool=False
        self._domains_to_remesh:Set[MeshTemplate]=set()

        self.max_residuals=1e10
        self.max_newton_iterations=10
        self.newton_solver_tolerance=1e-8
        self._call_output_after_adapt:bool=False

        #: Spatial adaption steps for the initial condition. If set to ``None``, we refine initially up to :py:attr:`max_refinement_level`.
        self.initial_adaption_steps:Union[None,int]=None #Adapting in the first step
        self.remove_macro_elements_after_initial_adaption:Union[bool,Literal["auto"]]="auto" # "auto" means: Only if the coordinates are free

        #: Minimum error of all meshes for spatial adaptivity. If the error is below this threshold, we may unrefine locally.
        self.min_permitted_error:float=0.0001	#Some defaults for the meshes
        #: Maximum error of all meshes for spatial adaptivity. If the error is above this threshold, we must refine locally.
        self.max_permitted_error:float=0.001
        #: Maximum number of refinements of all meshes. 
        self.max_refinement_level:int=8
        #: Minimum refinement level of all meshes. 
        self.min_refinement_level:int=0

        self._meshtemplate_list:List[MeshTemplate]=[]
        self._meshdict={}
        self._residual_mapping_functions:List[Callable[[str,Expression],Union[Expression,Dict[str,Expression]]]]=[]

        self._named_vars:Dict[str,ExpressionOrNum]={}

        self._coordinate_system=cartesian

        self.scaling:Dict[str,Union[str,ExpressionOrNum]]={} #Add scales here, i.e. spatial=1*centi*meter, temporal=...
        self.scaling["time"]="temporal"
        self.scaling["coordinate"]="spatial" #Link the default fields to the main scales
        self.scaling["coordinate_x"]="spatial"
        self.scaling["coordinate_y"]="spatial"
        self.scaling["coordinate_z"]="spatial"

        self.scaling["mesh"]="spatial" #Link the default fields to the main scales
        self.scaling["mesh_x"]="spatial"
        self.scaling["mesh_y"]="spatial"
        self.scaling["mesh_z"]="spatial"

        self.scaling["lagrangian"] = "spatial"  # Link the default fields to the main scales
        self.scaling["lagrangian_x"] = "spatial"
        self.scaling["lagrangian_y"] = "spatial"
        self.scaling["lagrangian_z"] = "spatial"


        self._lasolver=get_default_linear_solver()

        self._num_threads:Optional[int]=None # Default
        self._eigensolver=get_default_eigen_solver()

        self._runmode="delete"
        self._continue_initialized=False
        self._where_expression="True"

        self._dump_header = "pyoomph_dump"
        self._dump_version = "0.0.1"
        self._last_bc_setting="init"

        self._output_step:int=0
        self._continue_section_step:int=0
        self._continue_section_step_loaded:int=0
        self._nondim_time_after_last_run_statement=0 # Required for continue

        self._interfacemeshes:List[InterfaceMesh]=[]
        self._last_eigenvalues:NPComplexArray=numpy.array([],dtype=numpy.complex128) #type:ignore
        self._last_eigenvectors:NPComplexArray=numpy.array([],dtype=numpy.complex128) #type:ignore
        self._last_eigenvalues_m:Optional[NPIntArray]=None
        self._azimuthal_mode_param_m=None
        self._azimuthal_stability=_AzimuthalStabilityInfo()
        self._bifurcation_tracking_parameter_name:Optional[str]=None
        self._improved_pitchfork_tracking_coordinate_system:"OptionalCoordinateSystem"=None
        self._improved_pitchfork_tracking_position_coordinate_system:"OptionalCoordinateSystem"=None
        self._shared_shapes_for_multi_assemble=False
        self._setup_azimuthal_stability_code=False
        self._solve_in_arclength_conti=None

        self._last_arclength_parameter=None
        self._taken_already_an_unsteady_step=False
        self._last_step_was_stationary=None
        self._already_set_ic = False
        self._resetting_first_step=False
        
        #: Flag indicating whether to call remeshing when necessary. Can be set to ``False`` to disable remeshing, e.g. when tracking bifurcations, it is better to check it manually invoking the remeshing method :py:meth:`remesh_handler_during_continuation` after each solve.
        self.do_call_remeshing_when_necessary:bool=True

        self.default_timestepping_scheme:Literal["BDF2","BDF1","Newmark2"]="BDF2"

        self.default_spatial_integration_order:Union[int,None] = None

        self._equation_system:EquationTree

        self.timestepper = _pyoomph.MultiTimeStepper(True)
        self.add_time_stepper_pt(self.timestepper)

        #: Set this to a (list of ) plotter(s) to automatically plot on :py:meth:`output` calls. If set to ``None``, no plotting will be done.
        self.plotter:Optional[Union[List["MatplotlibPlotter"],"MatplotlibPlotter"]]=None
        self.plot_in_dedicated_process:bool=False
        self._plotting_process:Optional[subprocess.Popen]=None
        self.latex_printer:Optional[_pyoomph.LaTeXPrinter]=None

        self.write_states:bool=True
        self.states_compression_level:Union[int,None]=6
        self.eigen_data_in_states:Union[int,bool]=False # Either True (all calced eigenvalues/vectors or a number to limit the number of stored eigendata)
        self.continuation_data_in_states:bool=False
        self.additional_equations:Union[Literal[0],"EquationTree"]=0

        self.default_1d_file_extension:Union[Literal["txt","mat"],List[Literal["txt","mat"]]]="txt"

        self.always_take_one_newton_step=True

        self._mesh_data_cache=MeshDataCacheStorage()
        self.eigenvector_position_scale:float=1 # if eigenmode="real" or "imag", we shift the positions multiplied with this factor (for "abs" or "angle") is is not done
        self._abort_current_run=False

        self._custom_assembler:Optional["CustomAssemblyBase"]=None

        self.default_ccode_expression_mode:str="" # Try to factor all expressions with "factor"
        self.extra_compiler_flags:List[str]=[]

    # Use weak(u,psi) instead of vectorial U*Psi for the symmetry-breaking constraint
    def improve_pitchfork_tracking_on_unstructured_meshes(self,coord_sys:"OptionalCoordinateSystem"=None,pos_coord_sys:"OptionalCoordinateSystem"=None):
        self._improved_pitchfork_tracking_on_unstructured_meshes=True
        self._improved_pitchfork_tracking_coordinate_system=coord_sys
        self._improved_pitchfork_tracking_position_coordinate_system=pos_coord_sys
        #self.enable_store_local_dof_pt_in_elements()

    def abort_current_run(self):
        """If called within a run(...) statement, e.g. from some action_{after/before}_* methods, the run will abort
        """
        self._abort_current_run=True

    def can_continue_section(self, id:Optional[str]=None) -> bool:
        if id is not None:
            raise RuntimeError("TODO: id for continue sections")
        if not self._initialised:
            self.initialise()

#		if self.write_states:
#			raise RuntimeError("Section grouping by can_continue_section works only with write_states=False")

        if self._runmode != "continue":

            statedir:str = os.path.join(self.get_output_directory(), "_states")
            Path(statedir).mkdir(parents=True, exist_ok=True)
            statefname:str = os.path.join(statedir, "state_{:06d}.dump".format(self._continue_section_step))
            self.save_state(statefname)
            self._continue_section_step += 1
            return False


        if self._continue_section_step_loaded>self._continue_section_step:
            self._continue_section_step += 1
            print("SKIPPING CONTINUE SECTION")
            return True
        else:
            return False
        
    # Shortcut to add a (GlobalLagrangeMultiplier(name=equation_contribution)+Scaling(name=scaling)+TestScaling(name=testscaling))@domain and return var(name,domain=domain),testfunction(name,domain=domain)
    def add_global_dof(self,name:str,equation_contribution:ExpressionOrNum=0,*,scaling:ExpressionNumOrNone=None,testscaling:ExpressionNumOrNone=None,domain:str="globals",only_for_stationary_solve:bool=False,initial_condition:ExpressionNumOrNone=None):
        """
        Add a global degree of freedom, e.g. a global Lagrange multiplier to the problem.

        Args:
            name (str): The name of the degree of freedom.
            equation_contribution (ExpressionOrNum): The global contribution of the degree of freedom to its equation. Defaults to 0.
            scaling (ExpressionNumOrNone, optional): The scaling factor for the degree of freedom. Defaults to None.
            testscaling (ExpressionNumOrNone, optional): The scaling factor for the test function. Defaults to None.
            domain (str, optional): The domain to which the degree of freedom belongs. Defaults to "globals".
            only_for_stationary_solve (bool, optional): Whether the degree of freedom is only used for stationary solves, if set, it will be 0 and pinned during transient solves. Defaults to False.
            initial_condition (ExpressionNumOrNone, optional): The initial condition for the degree of freedom. Defaults to None.

        Returns:
            tuple: A tuple containing the variable and test function associated with the degree of freedom.
        """            
        from ..generic.codegen import GlobalLagrangeMultiplier,var,testfunction
        from ..equations.generic import Scaling,TestScaling,InitialCondition
        neweqs=GlobalLagrangeMultiplier(**{name:equation_contribution},only_for_stationary_solve=only_for_stationary_solve)
        if scaling is not None:
            neweqs+=Scaling(**{name:scaling})
        if testscaling is not None:
            neweqs+=TestScaling(**{name:testscaling})
        if initial_condition is not None:
            neweqs+=InitialCondition(**{name:initial_condition})
        self+=neweqs@domain
        return var(name,domain=domain),testfunction(name,domain=domain)


    def get_cached_mesh_data(self,msh:Union[str,AnySpatialMesh],nondimensional:bool=False,tesselate_tri:bool=True,eigenvector:Optional[Union[int,Sequence[int]]]=None,eigenmode:MeshDataEigenModes="abs",history_index:int=0,with_halos:bool=False,operator:Optional[MeshDataCacheOperatorBase]=None,discontinuous:bool=False,add_eigen_to_mesh_positions:bool=True) -> "MeshDataCacheEntry":
        """Return the current data (i.e. values) of a mesh. These are cached in case they are required multiple times, e.g. for plotting and output. 
        The cache is invalidated whenever we solve the problem or set some initial condition.  

        Args:
            msh (Union[str,AnySpatialMesh]): Mesh object or mesh name
            nondimensional (bool, optional): Getting nondimensional values instead of dimensional ones. Defaults to False.
            tesselate_tri (bool, optional): Split quad elements into tris. Helpful e.g. for plotting via matplotlib, which requires triangular meshes. Defaults to True.
            eigenvector (Optional[Union[int,Sequence[int]]], optional): If not None, we can obtain the values of the eigenfunction with the given index. Defaults to None.
            eigenmode (MeshDataEigenModes, optional): Since eigenfunctions are in general complex, we must select the desired projection to real numbers here in case of eigenvector!=None. Defaults to "abs".
            history_index (int, optional): Set to 1 or 2 to access the previous time steps. Defaults to 0.
            with_halos (bool, optional): Include halos to the output. Defaults to False.
            operator (Optional[MeshDataCacheOperatorBase], optional): Apply an operator on the cache, e.g. to add eigenvectors or extrude it in 3d. Defaults to None.

        Returns:
            MeshDataCacheEntry: The combined information of the mesh cache
        """
        if isinstance(msh,str):
            msh=self.get_mesh(msh)
        return self._mesh_data_cache.get_data(msh,nondimensional=nondimensional,tesselate_tri=tesselate_tri,eigenvector=eigenvector,eigenmode=eigenmode,history_index=history_index,with_halos=with_halos,operator=operator,discontinuous=discontinuous,add_eigen_to_mesh_positions=add_eigen_to_mesh_positions)

    def invalidate_cached_mesh_data(self,only_eigens:bool=False):
        """Mesh data is cached for potentially multiple usage (e.g. plotting and output to file). Whenever we change anything (e.g. changing values), we must hence invalidate the cache.

        Args:
            only_eigens (bool, optional): Only flush the cache of eigenfunctions, not of the current state. Defaults to False.
        """
        self._mesh_data_cache.clear(only_eigens)

    def set_tolerance_for_singular_jacobian(self,tol:float):
        _pyoomph.set_tolerance_for_singular_jacobian(tol)    

    def add_equations(self,eqs:EquationTree)->None:
        """Add equations to the system. Should be called within the define_problem() method.

        Args:
            eqs (EquationTree): The equations (restricted to a domain) to add to the problem. 
        """
        if not isinstance(eqs,EquationTree): #type: ignore
            err=ValueError("Cannot add "+str(eqs)+' to the system. Equations need to be restricted via <equation> @ "<name in equation tree>"')
            eqs.add_exception_info(err)
        if not self._during_initialization:
            raise RuntimeError("You cannot use add_equations outside define_problem (or in functions called from there). Use additional_equations+=... instead, if you want to add something before initialization.")
        if not hasattr(self,"_equation_system") or self._equation_system is None:
            self._equation_system=eqs
        else:
            self._equation_system+=eqs

    def get_equations(self,path:str,error_if_not_found:bool=True)->Optional[BaseEquations]:
        """Return the equations added at the specified path.

        Args:
            path (str): Path to the domain
            error_if_not_found (bool, optional): Raise an error if the domain path is not valid. Defaults to True.

        Raises:
            RuntimeError: In case you specify a path where not equations are defined and error_if_not_found==True, you will get this error

        Returns:
            Optional[BaseEquations]: The equations at the desired domain path. If error_if_not_found==False, it is None if there are no equations at the desired path specified.
        """
        if self._equation_system is None:
            return None
        eqtree=self._equation_system.get_by_path(path)
        if eqtree is None:
            if error_if_not_found:
                raise RuntimeError("Cannot get equations at "+path)
            else:
                return None
        return eqtree._equations


    @overload
    def assemble_jacobian(self,with_residual:Literal[True]=...,which_one:str=...)->Tuple[List[float],DefaultMatrixType]: ...

    @overload
    def assemble_jacobian(self,with_residual:Literal[False],which_one:str)->DefaultMatrixType: ...
    
    def assemble_jacobian(self,with_residual:bool=True,which_one:str="")->Union[DefaultMatrixType,Tuple[List[float],DefaultMatrixType]]:
        res, n, _, _, J_values_arr, J_colindex_arr, J_row_start_arr=self._assemble_residual_jacobian(which_one)
        J = scipy.sparse.csr_matrix((J_values_arr, J_colindex_arr, J_row_start_arr), shape=(n, n)) #type:ignore
        if with_residual:
            return res,J #type:ignore
        else:
            return J

    def remove_equations(self, path:str, of_type:Optional[Type[BaseEquations]]=None, only_if:Callable[[BaseEquations],bool]=lambda eqn: True,fail_if_not_exist:bool=False):
        eqtree = self._equation_system.get_by_path(path)
        if eqtree is None:
            if fail_if_not_exist:
                raise RuntimeError("No equations found at the path "+str(path))
            else:
                return
        eqs = eqtree._equations 
        if isinstance(eqs, CombinedEquations):
            if (of_type is None) or (isinstance(of_type, CombinedEquations)):
                if only_if(eqs):
                    eqtree._equations = DummyEquations() 
                    eqtree._equations._problem=self
            else:
                if of_type is None:
                    if only_if(eqs):
                        eqtree._equations = DummyEquations() 
                        eqtree._equations._problem=self
                else:
                    eqs._subelements = [e for e in eqs._subelements if not (isinstance(e, of_type) and only_if(e))] 
                    if len(eqs._subelements) == 0: 
                        eqtree._equations = DummyEquations() 
                        eqtree._equations._problem=self
        else:
            if (of_type is not None):
                if not isinstance(eqs, of_type):
                    return
            if eqs is not None and only_if(eqs):
                eqtree._equations = DummyEquations() 
                eqtree._equations._problem=self

    def get_default_timestepping_scheme(self,order:int) -> Literal['Newmark2', 'BDF2', 'BDF1']:
        if order==2:
            return "Newmark2"
        else:
            return self.default_timestepping_scheme

    def get_default_spatial_integration_order(self) -> int:
        if self.default_spatial_integration_order is None:
            return 0
        else:
            return self.default_spatial_integration_order

    #This must be used via "with problem.custom_adapt(): ..."
    def custom_adapt(self,skip_init_call:bool=False) -> _CustomAdaptWithHelper:
        return _CustomAdaptWithHelper(self,skip_init_call)

    def get_output_directory(self,relative_path:Optional[str]=None)->str:
        """Return the output directory of the problem. Set it with set_output_directory(). Otherwise, it will default to the name of the invoked script minus the extension .py.
        Optionally, you can add a relative path to assemble e.g. a file name within the output directory.

        Args:
            relative_path (Optional[str], optional): If set, we join this relative additional path to the output directory. Defaults to None.

        Returns:
            str: The output directory of the problem (potentially joined with the additionally passed relative_path)
        """
        if relative_path is not None:
            return os.path.join(self.get_output_directory(),relative_path)
        else:
            return self._outdir

    def set_output_directory(self,d:str)->None:
        """Change the output directory of the problem. Note: It should not be changed after the problem is initialised.

        Args:
            d: Output directory
        """
        self._outdir=d

    def has_named_var(self, name:str)->bool:
        return name in self._named_vars.keys()

    def get_named_var(self, name:str, default:Optional[ExpressionOrNum]=None)->ExpressionNumOrNone:
        return self._named_vars.get(name, default)

    def define_named_var(self, **kwargs:ExpressionOrNum):
        """Named vars are global expressions that are bound to a name. 
        
        You can e.g. use define_named_var(temperature=20*celsius) to define a temperature variable at problem level. When an equation tried to expand var("temperature") and no field "temperature" is defined on the current domain or its parents, the variable will be expanded by the global variable.  
        """
        for name,expr in kwargs.items():
            if not isinstance(expr,_pyoomph.Expression):
                expr=_pyoomph.Expression(expr)
            self._named_vars[name]=expr

    def __enter__(self):
        return self

    def release(self):
        def release_spatial_mesh(m:AnySpatialMesh):
            cg=m.get_code_gen()
            cg._code=None 
            cg._problem=None
            for im in m._interfacemeshes.values(): 
                release_spatial_mesh(im)
     
            m._interfacemeshes.clear() 
            m._eqtree._equations=None 
            m._eqtree=None #type:ignore

        for m in self._meshdict.values():
            if not isinstance(m,ODEStorageMesh):
                release_spatial_mesh(m)
            else:
                m._eqtree=None 
                m._element=None 

        self._lasolver:Optional[Union[str,GenericLinearSystemSolver]] = None
        self._eigensolver:Optional[Union[str,GenericEigenSolver]] = None
        self._meshtemplate_list = []
        self._meshdict:Dict[str,"AnyMesh"] = {}
        self.invalidate_cached_mesh_data()
        self.invalidate_eigendata()        
        self.flush_sub_meshes()
        self._unload_all_dlls()
        gc.collect()
        gc.collect()
        gc.collect()


    def __exit__(self, type, value, traceback): #type:ignore
        if isinstance(type,Exception):
            raise type
        else:
            self.release()


    @overload
    def get_mesh(self, name:str,return_None_if_not_found:Literal[False]=...)->AnySpatialMesh: ...

    @overload
    def get_mesh(self, name:str,return_None_if_not_found:Literal[True])->Optional[AnySpatialMesh]: ...

    def get_mesh(self, name:str,return_None_if_not_found:bool=False)->Optional[AnySpatialMesh]:
        """Get the mesh at the desired domain path. Invokes initialization if the problem is not initialised!

        Args:
            name (str): Domain path of the mesh
            return_None_if_not_found (bool, optional): If True, None will be returned if the given domain path is invalid. If False, an error will be raised in that case. Defaults to False.

        Raises:
            RuntimeError: Raised if there is no mesh at the given domain path in case of return_None_if_not_found==False (default). Same happens if an ODE domain is tried to be accessed like this. Use get_ode() for this.

        Returns:
            Optional[AnySpatialMesh]: The mesh at the domain path. None can only be returned if return_None_if_not_found==True and the domain path is invalid.
        """
        if not self._initialised:
            self.initialise()
        splt=name.split("/")
        if len(splt)==1:
            if return_None_if_not_found:
                res=self._meshdict.get(name,None)
                if isinstance(res,ODEStorageMesh):
                    return None
                else:
                    return res
            elif name in self._meshdict.keys():
                res=self._meshdict[name]
                if isinstance(res,ODEStorageMesh):
                    raise RuntimeError("There is an ODE, not a spatial Mesh at "+name+". So please use get_ode instead of get_mesh here")
                else:
                    return res
            else:
                raise RuntimeError("Cannot get mesh "+str(name)+", since it is not defined")
        else:
            msh=self._meshdict.get(splt[0],None)
            if msh is None:
                if return_None_if_not_found:
                    return None
                else:
                    raise RuntimeError("Cannot get mesh "+name+" since parent mesh "+splt[0]+" was not found")            
            if isinstance(msh,ODEStorageMesh):
                if return_None_if_not_found:
                    return None
                else:
                    raise RuntimeError("There is an ODE, not a spatial Mesh at "+name+". So please use get_ode instead of get_mesh here")
            if return_None_if_not_found:
                return msh.get_mesh("/".join(splt[1:]),return_None_if_not_found=True)
            else:
                return msh.get_mesh("/".join(splt[1:]),return_None_if_not_found=False)

    def get_ode(self,name:str)->ODEStorageMesh:
        """Return the ODE object at the given domain path. Invokes initialization if the problem is not initialised!

        Args:
            name (str): Domain path of the ODE

        Raises:
            RuntimeError: If the given domain path is invalid or a spatial mesh is defined at this domain, this error will occur.

        Returns:
            ODEStorageMesh: The ODE object at the given domain path
        """
        if not self._initialised:
            self.initialise()
        res=self._meshdict.get(name, None)
        if res is None:
            raise RuntimeError("No ODE domain with name "+str(name)+" in the system")
        if not isinstance(res,ODEStorageMesh):
            raise RuntimeError("You tried to get an ODE with name "+str(name)+", but apparently, this is not an ODE!")
        return res

    def get_all_values_at_current_time(self,with_pos:bool)->Tuple[NPFloatArray,List[bool],NPFloatArray]:
        dofs,positional_dof=self.get_current_dofs()
        pinned=self.get_current_pinned_values(with_pos)
        return numpy.array(dofs),positional_dof,numpy.array(pinned) #type:ignore

    def set_all_values_at_current_time(self,dofs:Union[NPFloatArray, List[float]],pinned:Union[NPFloatArray, List[float]],with_pos:bool):
        self.set_current_dofs(dofs) #type:ignore
        self.set_current_pinned_values(pinned,with_pos) #type:ignore


    def setup_pinned_values_of_eigenfunction(self,pv:NPFloatArray,n:int,mode:"MeshDataEigenModes")->NPFloatArray:	#Can be customised
        return 0.0*pv #type:ignore	 # Default: All pinned values are zero

    @overload
    def set_eigenfunction_as_dofs(self,n:int,*,mode:"MeshDataEigenModes"="abs",additive_mesh_positions:bool=True,perturb_amplitude:Literal[None]=...)->Tuple[NPFloatArray,NPFloatArray]: ...
    
    @overload
    def set_eigenfunction_as_dofs(self,n:int,*,mode:"MeshDataEigenModes"="abs",additive_mesh_positions:bool=True,perturb_amplitude:float)->Tuple[NPFloatArray,NPFloatArray,float]: ...

    def set_eigenfunction_as_dofs(self,n:int,*,mode:"MeshDataEigenModes"="abs",additive_mesh_positions:bool=True,eigenvector_position_scale:Optional[float]=None,perturb_amplitude:Optional[float]=None)->Union[Tuple[NPFloatArray,NPFloatArray,float],Tuple[NPFloatArray,NPFloatArray]]:
        if n>=len(self._last_eigenvectors):
            raise RuntimeError("Cannot set eigenfunction "+str(n)+" as dofs, since we have calculated only "+str(len(self._last_eigenvectors))+" eigenfunctions")
        with_pos=not additive_mesh_positions
        actual_dofs,positional_dofs,pinned_values=self.get_all_values_at_current_time(with_pos)
        if eigenvector_position_scale is None:
            eigenvector_position_scale=self.eigenvector_position_scale
        newpinned=self.setup_pinned_values_of_eigenfunction(numpy.array(pinned_values),n,mode) #type:ignore
        #print(newpinned)
        pert=self._last_eigenvectors[n]
        if len(pert)<len(actual_dofs):
            pert=numpy.pad(pert,(0,len(actual_dofs)-len(pert))) #type:ignore
        if mode=="abs":
            newdofs:NPFloatArray=numpy.absolute(pert)
        elif mode=="real":
            newdofs=numpy.real(pert) #type:ignore
        elif mode=="imag":
            newdofs=numpy.imag(pert) #type:ignore
        elif mode=="angle":
            newdofs=numpy.angle(pert) #type:ignore
        else:
            raise ValueError("Unknown eigenvector -> dof mode : "+str(mode))

        pos_indicator = numpy.array(positional_dofs, dtype="float64") #type:ignore
        if (mode=="real" or mode=="imag") and additive_mesh_positions:
            newdofs=newdofs*(1-pos_indicator)+pos_indicator*(eigenvector_position_scale*newdofs+actual_dofs) #type:ignore # Shift only in real or imag mode
        elif additive_mesh_positions:
            newdofs=newdofs*(1-pos_indicator)+pos_indicator*actual_dofs # Cannot shift in a good way here, take the old ones        
        aampl=1.0
        if perturb_amplitude is not None:
            if mode!="real" and mode!="imag":
                raise RuntimeError("Perturb mode only works in real or imag")
            aampl:float=numpy.amax(newdofs)-numpy.amin(newdofs) #type:ignore
            if aampl<1e-20:
                newdofs=actual_dofs
            else:
                newdofs=perturb_amplitude*newdofs/aampl+actual_dofs
            newpinned=pinned_values.copy()
            
        self.set_all_values_at_current_time(newdofs,newpinned,with_pos)
        if perturb_amplitude is not None:
            return actual_dofs, pinned_values,aampl #type:ignore
        else:
            return actual_dofs,pinned_values #type:ignore


    def get_coordinate_system(self) -> BaseCoordinateSystem:
        """
        Get the coordinate system set at problem level.

        Returns:
            BaseCoordinateSystem: The coordinate system at problem level.
        """
        return self._coordinate_system

    def set_coordinate_system(self,csys:Union[Literal["axisymmetric","axisymmetric_flipped","cartesian","radialsymmetric"],BaseCoordinateSystem]):                
        """Set the default coordinate system at problem level. 
        You can specify coordinate systems also at equation level, but if you don't do, the coordinate system will default to this one.

        Args:
            csys (Union[Literal["axisymmetric","axisymmetric_flipped","cartesian","radialsymmetric"],BaseCoordinateSystem]): The coordinate system to set as default.

        Raises:
            RuntimeError: Raised in case we do not set a valid coordinate system 
        """
        if csys is None:
            raise RuntimeError("Cannot set the problem coordinate system to None")
        if isinstance(csys,str):
            if csys=="axisymmetric":
                csys=axisymmetric
            elif csys=="axisymmetric_flipped":
                csys=axisymmetric_flipped
            elif csys=="cartesian":
                csys=cartesian
            elif csys=="radialsymmetric":
                csys=radialsymmetric
            else:
                raise RuntimeError("Unknown coordinate system: "+csys)

        self._coordinate_system=csys


    @overload
    def get_scaling(self,s:str,none_if_not_set:Literal[False]=...)->ExpressionOrNum: ...
    @overload
    def get_scaling(self,s:str,none_if_not_set:Literal[True])->ExpressionNumOrNone: ...

    def get_scaling(self,s:str,none_if_not_set:bool=False)->ExpressionNumOrNone:
        """
        Get the scaling factor for the problem variables for nondimensionalization.

        Args:
            s: Name of the scale to get.
            none_if_not_set: Returns None if this scaling is not set. Otherwise, the default scale 1 is returned. Defaults to ``False``.

        Returns:
            Scaling set by :py:meth:`~Problem.set_scaling` or None if ``none_if_not_set==True`` and the scale is not set.
        """
        scale=s
        while isinstance(scale,str):
            scale=self.scaling.get(scale,None if none_if_not_set else 1)
            if scale is None:
                return None
        if isinstance(scale,int) or isinstance(scale,float):
            scale=_pyoomph.Expression(scale)
        return scale

    def set_scaling(self,**kwargs:Union[ExpressionOrNum,str])->None:
        """
        Set the scaling factors for the problem variables for nondimensionalization.
        You can provide also scaling at equation level, but if not set there, it will ultimately default to the problem level scaling.
        Particular scales are ``"temporal"`` for the time and ``"spatial"`` for the spatial coordinates.

        Parameters:
            **kwargs: Keyword arguments specifying the scaling factors.
                The keys are the variable names, and the values are either numerical scaling factors
                or string expressions. In the latter case, we can set one scaling to another one, e.g.
                
                    ``set_scaling(u=1*meter/second,v="u")`` 
                
                would set the scaling of "v" to the one of "u"
        """            
        for k,v in kwargs.items():
            if type(v)==str:
                continue
            elif isinstance(v,_pyoomph.Expression):
                self.scaling[k]=v.evalf()
            else:
                self.scaling[k]=v


        for k,v in kwargs.items():
            if type(v)!=str:
                continue
            self.scaling[k]=v


    def set_eigensolver(self,solv:Union[str,GenericEigenSolver]):
        """
        Set the eigensolver backend. "scipy", "pardiso", "slepc" are available (the latter two only if the packages MKL and/or petsc4py/slepc4py are installed)

        Returns:
            The eigenproblem solver instance after setting
        """
        if isinstance(solv,str):
            solv=GenericEigenSolver.factory_solver(solv,self)
        self._eigensolver=solv        
        print("EIGEN SOLVER WAS SET TO: "+self._eigensolver.idname)
        return self._eigensolver

    def set_linear_solver(self,solv:Union[str,GenericLinearSystemSolver]):
        
        """
        Set the linear solver backend. "scipy", "umfpack", "pardiso", "petsc" are available (the latter two only if the packages MKL and/or petsc4py are installed)

        Returns:
            The linear solver instance after setting
        """
        
        if isinstance(solv,str):
            solv=GenericLinearSystemSolver.factory_solver(solv,self)
        if self._num_threads is not None:
            solv.set_num_threads(self._num_threads)
        self._lasolver=solv        
        print("LINEAR SOLVER WAS SET TO: "+self._lasolver.idname)
        return self._lasolver

    def set_num_threads(self,nthread:Optional[int]):
        self._num_threads=nthread
        if self._lasolver is not None:
            if isinstance(self._lasolver,str):
                self.set_linear_solver(self._lasolver)
            else:
                self._lasolver.set_num_threads(self._num_threads)


    def get_eigen_solver(self)->GenericEigenSolver:
        """Get the eigenproblem solver instance.

        Returns:
            GenericEigenSolver: The currently used eigensolver
        """
        
        if self._eigensolver is None:
            self._eigensolver=get_default_eigen_solver()
        if isinstance(self._eigensolver,str):
            self._eigensolver=GenericEigenSolver.factory_solver(self._eigensolver,self)
        assert isinstance(self._eigensolver,GenericEigenSolver)
        return self._eigensolver


    def get_la_solver(self)->"GenericLinearSystemSolver":
        
        """Get the linear solver instance.

        Returns:
            GenericLinearSystemSolver: The currently used linear solver
        """
        
        if self._lasolver is None:
            self._lasolver=get_default_linear_solver()
        if isinstance(self._lasolver,str):
            self._lasolver=GenericLinearSystemSolver.factory_solver(self._lasolver,self)
        assert isinstance(self._lasolver,GenericLinearSystemSolver)
        return self._lasolver

    def _activate_solver_callback(self):
        _pyoomph.get_Solver_callback().set_problem(self) #type:ignore


    def is_initialised(self)->bool:
        """Returns whether the problem has been initialised or not.

        Returns:
            bool: True if already initialised, False otherwise
        """
        return self._initialised

    def output_at_increased_time(self,dt:Optional[ExpressionOrNum]=None)->None:
        """
        Increases the current time by the specified time step (dt, default scale_factor("temporal")) and calls the output method.
        Useful for Paraview PVD output of multiple stationary solutions, which otherwise overlays multiple outputs at the same time step.

        Args:
            dt (Optional[ExpressionOrNum]): The time step to increase the current time by. If not provided,
                the scaling factor for temporal is used.

        Returns:
            None
        """               
        if dt is None:
            dt=self.get_scaling("temporal")
        self.set_current_time(self.get_current_time()+dt)
        self.output()

    def perform_plot(self):
        if self._plotting_process is not None:
            raise RuntimeError("Should not end up here")
        if isinstance(self.plotter, list):
            for p in self.plotter:
                p._output_step = self._output_step
                if p.active:
                    p.plot()
        elif self.plotter is not None:
            self.plotter._output_step = self._output_step  
            if self.plotter.active:
                self.plotter.plot()

    def _update_output_scales(self):
        for _n,m in self._meshdict.items():
            m._setup_output_scales()
            if not isinstance(m,ODEStorageMesh):
                def recu_interf(m):
                    for _in,im in m._interfacemeshes.items():
                        im._setup_output_scales()
                        recu_interf(im)
                recu_interf(m)


    def output(self, stage: str = "", quiet: Optional[bool] = None) -> None:
        """
        Invoke an output of the current solution at the current time by calling all Output objects.

        Args:
            stage (str): The stage of the output, at the moment, only "" is meaninfull.
            quiet (bool, optional): Flag to control the verbosity of the output.

        Returns:
            None
        """
        if not self.is_initialised():
            self.initialise()
        if quiet is None:
            quiet = self.is_quiet()
        if not quiet:
            paramstr = ""
            paramnames = [pn for pn in self.get_global_parameter_names() if not pn.startswith("_")]
            if len(paramnames) > 0:
                paramstr = ". Parameters: " + ", ".join([n + "=" + str(self.get_global_parameter(n).value) for n in paramnames])
            if not self.is_distributed():
                if get_mpi_rank() == 0:
                    print("OUTPUT at t=" + str(self.get_current_time()) + paramstr)
            else:
                print("OUTPUT of proc " + str(get_mpi_rank()) + " at t=" + str(self.get_current_time()) + paramstr)
        self._equation_system._do_output(self._output_step, stage)

        if self.plotter is not None:
            if self._plotting_process is None:
                self.perform_plot()

        if self.write_states:
            statedir = os.path.join(self.get_output_directory(), "_states")
            Path(statedir).mkdir(parents=True, exist_ok=True)
            statefname = os.path.join(statedir, "state_{:06d}.dump".format(self._output_step))
            self.save_state(statefname)
            if self._plotting_process is not None:
                if self._plotting_process.poll() is not None:
                    raise RuntimeError("Plotting process failed. Have a look at " + self.get_output_directory("_dedicated_plotter_log.txt"))
                print("State file written, invoking plotting process")
                self._plotting_process.stdin.write((statefname + "\n").encode("utf-8"))
                self._plotting_process.stdin.flush()

            self._output_step += 1  # Write with the updated outstep here ??
        else:
            self._output_step += 1

        


    def init_output(self,redefined:bool=False):
        cinfo=None
        if redefined:
            cinfo={"redefined":True}
        if self._runmode=="continue":
            cinfo={"outstep":self._output_step,"dimtime":self.get_current_time(),"nondimtime":self.get_current_time(dimensional=False,as_float=True),"floattime":self.get_current_time(dimensional=True,as_float=False)}
        self._equation_system._init_output(continue_info=cinfo,rank=get_mpi_rank()) 


    def define_problem(self):
        """
        Define the problem by creating the mesh(es) and other necessary components.

        This method should be overridden by subclasses to define the specific problem.
        """
        pass
        #raise NotImplementedError("Please override the function define_problem to create the mesh(es) and so on")


    def flush_mesh_templates(self):
        self._meshtemplate_list=[]

    _TypeVarMeshTemplate=TypeVar("_TypeVarMeshTemplate",bound=MeshTemplate)
    def add_mesh(self,mesh:_TypeVarMeshTemplate)->_TypeVarMeshTemplate:
        """
        Adds a mesh to the problem. Based on the domain and boundary names of the mesh, equations can be added by using the same domain and boundary names.

        Args:
            mesh: Any mesh instance to be added (1d, 2d, 3d, etc.)

        Returns:
            Returns itself for chaining
        """
        self._meshtemplate_list.append(mesh)
        return mesh

    # Will be deprecated soon
    def add_mesh_template(self,mesh:_TypeVarMeshTemplate) -> _TypeVarMeshTemplate:
        """
        Same as self+=mesh or self.add_mesh(mesh). Will be deprecated soon.
        """
        return self.add_mesh(mesh)





    def relink_external_data(self):
        for ism in range(self.nsub_mesh()):
            submesh=self.mesh_pt(ism)
            if isinstance(submesh,(MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d,ODEStorageMesh,InterfaceMesh)):
                assert submesh._codegen is not None 
                submesh._codegen._perform_external_ode_linkage() 
                #if not isinstance(submesh,ODEStorageMesh):
                #    assert isinstance(submesh,(MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d,InterfaceMesh))
                submesh.ensure_external_data()


    def _adapt_with_interfacial_errors(self) -> Tuple[int, int]:
        #Resetting the element error override
        def reset(mesh:AnySpatialMesh):
            mesh._reset_elemental_error_max_override() 
            for _n,imesh in mesh._interfacemeshes.items():
                reset(imesh)
        for name,mesh in self._meshdict.items():
            if isinstance(mesh,ODEStorageMesh): continue
            reset(mesh)

        if True:
            #Now, we first have to go through all meshes at the deepest level in the tree
            def get_errs(mesh:AnySpatialMesh,depth:int):
                if not mesh.refinement_possible():
                    return
                if depth==0:
                    #print("GET ERRS ON MESH",mesh,mesh.get_name())
                    assert mesh._codegen is not None
                    mesh._codegen.calculate_error_overrides() 
                elif depth>0:
                    for _,imesh in mesh._interfacemeshes.items(): 
                        get_errs(imesh,depth-1)
            def override(mesh:AnySpatialMesh,depth:int):
                if not mesh.refinement_possible():
                    return
                if depth==0:
                    #print("OVERRIDE ON MESH",mesh,mesh.get_name())
                    if isinstance(mesh, InterfaceMesh):
                        mesh._override_bulk_errors_where_necessary() 
                elif depth>0:
                    for _n,imesh in mesh._interfacemeshes.items():
                        override(imesh,depth-1)

            for depth in reversed(range(3)):
                for name,mesh in self._meshdict.items():
                    if isinstance(mesh,ODEStorageMesh): continue
                    get_errs(mesh,depth)
            for depth in reversed(range(3)):
                for name,mesh in self._meshdict.items():
                    if isinstance(mesh,ODEStorageMesh): continue
                    override(mesh,depth)


            errs:Dict[str,List[float]]={}
            for name,mesh in self._meshdict.items():
                if isinstance(mesh,ODEStorageMesh): continue
                assert not isinstance(mesh,InterfaceMesh)
                errs[name]=mesh._merge_my_error_with_elemental_max_override()  
                #print("ERRS",name,errs[name])

            # Ensure same refinement at connected interfaces

            for name,mesh in self._meshdict.items():
                if isinstance(mesh,ODEStorageMesh): continue
                for inam,imesh in mesh._interfacemeshes.items():  
                    if imesh._opposite_interface_mesh is not None:  
                        if inam=="_internal_facets_":
                            raise RuntimeError("TODO: Adaption with internal facets")
                        # make sure that we override the mesh errors correctly

                        obm=imesh._opposite_interface_mesh._parent  
                        assert obm is not None and not isinstance(obm,InterfaceMesh)
                        my_maxerr=mesh.max_permitted_error
                        my_minerr = mesh.min_permitted_error
                        opp_maxerr = obm.max_permitted_error
                        opp_minerr = obm.min_permitted_error
                        for ie in imesh.elements():
                            be=ie.get_bulk_element()
                            obe=ie.get_opposite_bulk_element()
                            if obe._elemental_error_max_override<opp_minerr and be._elemental_error_max_override>=my_minerr:
                                obe._elemental_error_max_override=0.5*(opp_minerr+opp_maxerr)
                            elif obe._elemental_error_max_override>=opp_minerr and be._elemental_error_max_override<my_minerr:
                                be._elemental_error_max_override=0.5*(my_minerr+my_maxerr)
                        for i,e in enumerate(mesh.elements()):
                            errs[name][i]=max(errs[name][i],e._elemental_error_max_override)
                        for i,e in enumerate(obm.elements()):
                            errs[obm._name][i]=max(errs[obm._name][i],e._elemental_error_max_override) 


        # TODO: Ensure same refinement at connected interfaces

        nref=0
        nuref=0
        with self.custom_adapt(True):
            for name,errors in errs.items():
                mesh=self.get_mesh(name)
                if mesh.refinement_possible():
                    mesh.adapt_by_elemental_errors(errors)
                    if not self.is_quiet():
                        print("IN MESH "+name+" ref=",mesh.nrefined(),"unref=",mesh.nunrefined())
                    nref += mesh.nrefined()
                    nuref += mesh.nunrefined()
        return nref,nuref

    def _adapt(self) -> Tuple[int, int]:
        nref,nunref=self._adapt_with_interfacial_errors()
        return nref,nunref

    def compile_meshes(self):
        for _,mesh in self._meshdict.items():
            if isinstance(mesh,ODEStorageMesh):
                mesh._compile_bulk_equations() 
        for _,mesh in self._meshdict.items():
            if not isinstance(mesh,ODEStorageMesh):
                assert not isinstance(mesh,InterfaceMesh)
                mesh._compile_bulk_equations() 
        #Now all bulks are compiled
        #We now must add the interior facets contributions, if set
        for _,mesh in self._meshdict.items():
            if not isinstance(mesh,ODEStorageMesh):
                assert not isinstance(mesh,InterfaceMesh)
                has_interior_contribs=False
                eqs=mesh._eqtree.get_equations()
                for _,int_contrib in eqs._interior_facet_residuals.items():
                    if not is_zero(int_contrib):
                        has_interior_contribs=True
                        break
                if has_interior_contribs:
                    # Check if we already have an _interior_facets_ domain there
                    if "_internal_facets_" not in mesh._eqtree.get_children().keys():
                        raise RuntimeError("TODO: Auto create _interior_facets_ domain. For the time being, you have to add it by hand (just use eqs+=Equations()@'_internal_facets_').\nOr, even better, set self.requires_interior_facet_terms=True in the __init__ of the Equations class you add interior facet contributions.")
                        facetdom=EquationTree(InterfaceEquations(),parent=mesh._eqtree)                                                
                        mesh._eqtree._children["_internal_facets_"]=facetdom                        
                        facetdom._finalize_equations(mesh.get_problem())                        
                        facetmesh=InterfaceMesh(mesh.get_problem(),mesh,"_internal_facets_",facetdom)                                                
                        mesh._interfacemeshes["_internal_facets_"]=facetmesh
                        facetdom._mesh=mesh._interfacemeshes["_internal_facets_"]
                        facetdom.get_code_gen()._set_bulk_element(mesh._eqtree.get_code_gen())
                        cg_b=mesh._eqtree.get_code_gen()
                        nodal_dim=cg_b.get_nodal_dimension()                        
                        while nodal_dim==0 and cg_b.get_parent_domain() is not None:
                            cg_b=cg_b.get_parent_domain()                    
                        nodal_dim=cg_b.get_nodal_dimension()
                        facetdom.get_code_gen()._set_nodal_dimension(nodal_dim)                        
                        facetdom.get_code_gen()._do_define_fields(mesh._eqtree.get_code_gen().get_element_dimension()-1)
                        facetdom._create_dummy_domains_for_DG(mesh.get_problem())
                        
                        
                    internal_eqs=mesh._eqtree.get_child("_internal_facets_").get_equations()
                    for destination,int_contrib in eqs._interior_facet_residuals.items():
                        if destination in internal_eqs._additional_residuals.keys():
                            internal_eqs._additional_residuals[destination]+=int_contrib
                        else:
                            internal_eqs._additional_residuals[destination]=int_contrib


        for tree_depth in range(2):
            for _,mesh in self._meshdict.items():
                mesh._problem=self
                mesh._eqtree._equations.get_combined_equations()._problem=self
                if isinstance(mesh,ODEStorageMesh): continue
                mesh._pre_compile_interface_equations(tree_depth) 

            for _,mesh in self._meshdict.items():
                if isinstance(mesh,ODEStorageMesh): continue
                mesh._compile_interface_equations(tree_depth) 

            for _,mesh in self._meshdict.items():
                if isinstance(mesh,ODEStorageMesh): continue
                mesh._generate_interface_elements(tree_depth) 

        for _,mesh in self._meshdict.items():
            if isinstance(mesh, ODEStorageMesh): continue
            assert not isinstance(mesh,InterfaceMesh)
            mesh._link_periodic_corner_nodes()  

    

    def before_compile_equations(self, eqs: BaseEquations):
        eqs.get_current_code_generator().use_shared_shape_buffer_during_multi_assemble=self._shared_shapes_for_multi_assemble
        if self._improved_pitchfork_tracking_on_unstructured_meshes:
            for fn,_space in eqs._fields_defined_on_my_domain.items():
                u=nondim(fn,tag=["flag:only_base_mode"]) 
                utest=testfunction(fn,dimensional=False)
                # This will give a nice mass matrix! The Jacobian will be J_lk=psi^l*psi^k*dx                
                eqs.add_residual(weak(u,utest,coordinate_system=self._improved_pitchfork_tracking_coordinate_system),destination="_simple_mass_matrix_of_defined_fields")
            if eqs.get_current_code_generator()._coordinates_as_dofs and (eqs.get_parent_domain() is None) : # Only accumulate on the moving bulk domain
                u=nondim("mesh",tag=["flag:only_base_mode"]) 
                utest=testfunction("mesh",dimensional=False)
                cs=self._improved_pitchfork_tracking_coordinate_system
                if self._improved_pitchfork_tracking_position_coordinate_system:
                    cs=self._improved_pitchfork_tracking_position_coordinate_system
                eqs.add_residual(weak(u,utest,coordinate_system=cs),destination="_simple_mass_matrix_of_defined_fields")
            # Residuals not writtten to C, wont be used
            eqs.get_current_code_generator().set_ignore_residual_assembly("_simple_mass_matrix_of_defined_fields")
        if self._azimuthal_mode_param_m is not None:
            eqs.get_current_code_generator().set_ignore_residual_assembly(self._azimuthal_stability.real_contribution_name)
            eqs.get_current_code_generator().set_ignore_residual_assembly(self._azimuthal_stability.imag_contribution_name)

    def set_custom_assembler(self,assm:Optional["CustomAssemblyBase"]) -> None:
        self._custom_assembler=assm
        if self._custom_assembler:
            self.use_custom_residual_jacobian=True
            self._custom_assembler._set_problem(self)
            self._custom_assembler.initialize()
        else:
            self.use_custom_residual_jacobian=False

    def get_custom_residuals_jacobian(self, info:_pyoomph.CustomResJacInfo) -> None:
        if self._custom_assembler is None:
            raise RuntimeError("If you set use_custom_residual_jacobian=True, you must specify a custom assembler or override get_custom_residuals_jacobian yourself")
        if info.require_jacobian():
            res,J=self._custom_assembler.get_residuals_and_jacobian(True)
            assert res.dtype==numpy.float64 #type:ignore
            info.set_custom_residuals(res)
            assert J.indptr.dtype==numpy.int32 and J.indices.dtype==numpy.int32 and J.data.dtype==numpy.float64 #type:ignore
            info.set_custom_jacobian(J.data,J.indices,J.indptr) #type:ignore
        else:
            res=self._custom_assembler.get_residuals_and_jacobian(False)
            assert res.dtype==numpy.float64 #type:ignore
            info.set_custom_residuals(res)

    @overload
    def set_c_compiler(self,compiler_or_name:Literal["tcc"])->_pyoomph.CCompiler: ...

    @overload
    def set_c_compiler(self,compiler_or_name:Literal["system"])->"SystemCCompiler": ...

    def set_c_compiler(self,compiler_or_name:Union[str,BaseCCompiler])->Union[_pyoomph.CCompiler,BaseCCompiler]:
        """
        Selects the C compiler for the problem. 
        "tcc" is fast in compilation, but slower in execution. Good for setting up a problem class.
        "system" is slower in compilation, but faster in execution. Good for running the final problem.
        set_c_compiler("system").optimize_for_max_speed() makes it even faster by using compiler flags for maximum speed.

        Args:
            compiler_or_name (Union[str, BaseCCompiler]): The C compiler to use ("tcc" or "system" at the moment).

        Returns:
            Union[_pyoomph.CCompiler, BaseCCompiler]: The C compiler that was set.
        """      
                
        from .ccompiler import get_ccompiler
        if isinstance(compiler_or_name,str):
            if compiler_or_name=="tcc":
                if _pyoomph.has_tcc():
                    compiler_or_name="_internal_"
                else:
                    compiler_or_name="tccbox"
            elif compiler_or_name=="distutils":
                compiler_or_name="system"
            cc=get_ccompiler(compiler_or_name)
        else:
            cc=compiler_or_name
        self._set_ccompiler(cc)
        return self.get_ccompiler()


    def __iadd__(self,other:Union[MeshTemplate,EquationTree]):
        if self._initialised:
            raise RuntimeError("Cannot add anything to a problem once it is initialized!")
        if isinstance(other,MeshTemplate):
            self.add_mesh(other)
        elif isinstance(other,EquationTree):
            self.additional_equations+=other
        else:
            addinfo=""
            if isinstance(other,BaseEquations):
                addinfo="  -- You must restrict equations to a domain using e.g. @'domain'"

            raise RuntimeError("cannot add this to a Problem: " +str(other)+addinfo)
        return self

    def cmdline_desc(self) -> str:
        return "Generic Pyoomph Problem"

    def setup_cmd_line(self):              
        self.cmdlineparser = argparse.ArgumentParser(description=self.cmdline_desc())        
        self.cmdlineparser.add_argument('--petsc',help="use PETSc solver",action='store_true')
        self.cmdlineparser.add_argument('--pastix',help="use PaSTiX solver",action='store_true')
        self.cmdlineparser.add_argument('--superlu',help="use serial SuperLu solver",action='store_true')
        self.cmdlineparser.add_argument('--umfpack', help="use UMFPACK solver", action='store_true')
        self.cmdlineparser.add_argument('--pardiso', help="use Pardiso solver", action='store_true')
        self.cmdlineparser.add_argument('--mumps', help="use MUMPS solver", action='store_true')
        self.cmdlineparser.add_argument('--slepc',help="use SLEPc as eigensolver. Specify your own backend for the matrix inversion during eigensolve here",action="store_true")
        self.cmdlineparser.add_argument('--slepc_mumps',help="use SLEPc as eigensolver with MUMPS as backend",action="store_true")        
        self.cmdlineparser.add_argument('--arpack',action="store_true")
        self.cmdlineparser.add_argument('--tcc', help="use internal TCC compiler", action='store_true')
        self.cmdlineparser.add_argument('--distutils', help="use system C compiler detected by distutils", action='store_true')
        self.cmdlineparser.add_argument('--fast-math', help="activate fast math compiler flags (only with distutils, not with tcc)", action='store_true')        
        self.cmdlineparser.add_argument('--distribute',help="Distribute mesh in parallel",action='store_true')
        self.cmdlineparser.add_argument('--outdir', help="output directory",type=str)
        self.cmdlineparser.add_argument('--suppress_code_writing',help="do not write FEM codes. Useful for debugging",action='store_true')
        self.cmdlineparser.add_argument('-P','--parameter', help="Override some problem parameters",nargs='+', type=str)
        self.cmdlineparser.add_argument("--runmode",help="Selects the runmode ([d]elete and run, [o]verride and run, [c]ontinue, [p]lot again",type=str)
        self.cmdlineparser.add_argument("--recompile_on_continue",help="When using --runmode c, compilation and code writing is usually suppressed. You can recompile the code anyhow with this flag",action="store_true")
        self.cmdlineparser.add_argument("--verbose",help="Gives a lot of output",action='store_true')
        self.cmdlineparser.add_argument("--where",help="Python bool expression involving variables time or step. Only used in runmodes c and p",type=str,default="True")
        self.cmdlineparser.add_argument("--largest_residuals",help="Debug the largest residuals",type=int,default=self._debug_largest_residual)

    def parse_cmd_line(self):
        from ..materials.generic import MaterialProperties
        if self.ignore_command_line:
            self.cmdlineargs, self.further_cmdlineargs = self.cmdlineparser.parse_known_args(args="")
        else:
            self.cmdlineargs, self.further_cmdlineargs = self.cmdlineparser.parse_known_args()
        if self.cmdlineargs.superlu:
            if self.cmdlineargs.petsc or self.cmdlineargs.pastix or self.cmdlineargs.umfpack or self.cmdlineargs.pardiso or self.cmdlineargs.mumps:
                raise ValueError("Cannot set two solvers simultaneously")
            self.set_linear_solver("superlu")
        elif self.cmdlineargs.petsc:
            if self.cmdlineargs.superlu or self.cmdlineargs.pastix or self.cmdlineargs.umfpack or self.cmdlineargs.pardiso or self.cmdlineargs.mumps:
                raise ValueError("Cannot set two solvers simultaneously")
                import pyoomph.solvers.petsc
            self.set_linear_solver("petsc")
        elif self.cmdlineargs.umfpack:
            if self.cmdlineargs.petsc or self.cmdlineargs.pastix or self.cmdlineargs.superlu or self.cmdlineargs.pardiso or self.cmdlineargs.mumps:
                raise ValueError("Cannot set two solvers simultaneously")
            self.set_linear_solver("umfpack")
        elif self.cmdlineargs.pardiso:
            if self.cmdlineargs.petsc  or self.cmdlineargs.pastix or self.cmdlineargs.superlu or self.cmdlineargs.umfpack or self.cmdlineargs.mumps:
                raise ValueError("Cannot set two solvers simultaneously")
            self.set_linear_solver("pardiso")
        elif self.cmdlineargs.mumps:
            if self.cmdlineargs.petsc  or self.cmdlineargs.pastix or self.cmdlineargs.superlu or self.cmdlineargs.umfpack or self.cmdlineargs.pardiso:
                raise ValueError("Cannot set two solvers simultaneously")
            self.set_linear_solver("mumps")
        elif self.cmdlineargs.pastix:
            self.set_linear_solver("pastix")

        if self.cmdlineargs.tcc:
            if self.cmdlineargs.distutils:
                raise RuntimeError("Cannot set --tcc and --distutils together")
            self.set_c_compiler("tcc")
            if self.cmdlineargs.fast_math:
                raise RuntimeError("Cannot use --fast-math with --tcc")
        elif self.cmdlineargs.distutils:
            ccomp=self.set_c_compiler("system")
            if self.cmdlineargs.fast_math:
                ccomp.optimize_for_max_speed()
        elif self.cmdlineargs.fast_math:
            self.set_c_compiler("system").optimize_for_max_speed()

        if self.cmdlineargs.arpack:
            if self.cmdlineargs.slepc or self.cmdlineargs.slepc_mumps:
                raise RuntimeError("Cannot be used together: --arpack and --slepc/--slepc_mumps")
            self.set_eigensolver("scipy") # Not using the pardiso arpack then
        elif self.cmdlineargs.slepc or self.cmdlineargs.slepc_mumps:
            import pyoomph.solvers.petsc
            self.set_eigensolver("slepc")
            if self.cmdlineargs.slepc_mumps:
                eigsolv=self.get_eigen_solver()
                assert isinstance(eigsolv,pyoomph.solvers.petsc.SlepcEigenSolver)
                eigsolv.use_mumps()
                


        if self.cmdlineargs.outdir:
            self._outdir=self.cmdlineargs.outdir

        if self.cmdlineargs.suppress_code_writing:
            self._suppress_code_writing=True

        if self.cmdlineargs.verbose:
            _pyoomph.set_verbosity_flag(1)

        possible_runmodes=["continue","delete","overwrite","replot"]
        if self.cmdlineargs.runmode=="c" or self.cmdlineargs.runmode=="continue":
            self._runmode="continue"
        elif self.cmdlineargs.runmode=="d" or self.cmdlineargs.runmode=="delete":
            self._runmode="delete"
        elif self.cmdlineargs.runmode=="o" or self.cmdlineargs.runmode=="overwrite":
            self._runmode="overwrite"
        elif self.cmdlineargs.runmode=="p" or self.cmdlineargs.runmode=="replot":
            self._runmode="replot"
        elif self.cmdlineargs.runmode is not None:
            raise RuntimeError("Unknown runmode "+self.cmdlineargs.runmode+". Possible are "+", ".join(possible_runmodes))

        if not self._runmode in possible_runmodes:
            raise RuntimeError(
                "Unknown runmode " + self._runmode + ". Possible are " + ", ".join(possible_runmodes))

        if self._runmode=="continue" or self._runmode=="replot":
            self._suppress_code_writing=(not self.cmdlineargs.recompile_on_continue) or self._runmode=="replot"
            self._suppress_compilation=(not self.cmdlineargs.recompile_on_continue) or self._runmode=="replot"

        self._where_expression=self.cmdlineargs.where

        self._debug_largest_residual=self.cmdlineargs.largest_residuals
        if self._debug_largest_residual>0:
            self.enable_store_local_dof_pt_in_elements()

        if self.cmdlineargs.parameter is not None:
            for cmdset in self.cmdlineargs.parameter:

                splt=cmdset.split("=")
                varname=splt[0]
                mode="="
                if varname.endswith("*"):
                    mode="*"
                elif varname.endswith("/"):
                    mode="/"
                elif varname.endswith("+"):
                    mode="+"
                elif varname.endswith("-"):
                    mode="-"
                if mode!="=":
                    varname=varname[0:-1]
                val="=".join(splt[1:])
                splt_varname=varname.split(".")
                obj:Any=self
                current=None
                for i,v in enumerate(splt_varname[:-1]):
                    if isinstance(obj,dict) and not isinstance(obj,Problem):
                        if v in obj.keys():
                            obj=obj.get(v) #type:ignore
                        else:
                            found_in_dict_by_name=False
                            for dict_entry in obj.keys(): #type:ignore
                                print("CHECKING",dict_entry)  #type:ignore
                                if hasattr(dict_entry,"name") and getattr(dict_entry,"name")==v: #type:ignore
                                    if found_in_dict_by_name:
                                        raise RuntimeError("Found two dict key entries with property name == '"+str(v)+"' in "+self.__class__.__name__ + "." + ".".join(splt_varname[:i + 1]))
                                    found_in_dict_by_name=True
                                    obj=dict_entry

                            if not found_in_dict_by_name:
                                raise RuntimeError("Cannot set parameter " + varname + " due to undefined property " + self.__class__.__name__ + "." + ".".join(splt_varname[:i + 1]))
                    else:
                        try:
                            obj=getattr(obj,v)
                        except:
                            raise RuntimeError("Cannot set parameter "+varname+" due to undefined property "+self.__class__.__name__+"."+".".join(splt_varname[:i+1]))

                if isinstance(obj,dict):
                    current = obj[splt_varname[-1]] #type:ignore
                elif hasattr(obj,splt_varname[-1]):
                    current=getattr(obj,splt_varname[-1])
                elif isinstance(obj,Problem) and splt_varname[-1] in obj.get_global_parameter_names():
                    current=obj.get_global_parameter(splt_varname[-1])
                else:
                    raise RuntimeError("Cannot set undefined property/parameter "+".".join(splt_varname)+". Currently at "+str(obj)+" and trying to access "+str(splt_varname[-1])+"\nFollowing properties are known:"+str(dir(obj)))
                
                if not self.is_quiet():
                    print("SETTING PARAMETER", varname,"FROM",current, "TO",val) #type:ignore
                #TODO: Complete this
                if isinstance(current,int):
                    if isinstance(current,bool):
                        if val=="True":
                            newvalue=True
                        elif val=="False":
                            newvalue=False
                        else:
                            raise RuntimeError("Cannot set the bool property "+varname+" to "+str(val))
                    else:
                        try:
                            newvalue=int(val)
                        except ValueError:
                            try:
                                newvalue=float(val)
                            except ValueError:
                                raise RuntimeError("Cannot set the integer property "+varname+" to "+str(val))
                elif isinstance(current,float):
                    try:
                        newvalue = float(val)
                    except ValueError:
                        raise RuntimeError("Cannot set the float property " + varname + " to " + str(val))
                elif isinstance(current,_pyoomph.Expression):
                    Pi=pi #type:ignore
                    try:
                        newvalue=eval(val)
                    except Exception as e:
                        raise RuntimeError("Cannot set the property " + varname + " to " + str(val)+"\n"+str(e))
                elif isinstance(current,str):
                    newvalue=val
                elif isinstance(current,_pyoomph.GiNaC_GlobalParam):
                    try:
                        newvalue=float(val)
                    except:
                        raise ValueError("Cannot set a global parameter value to "+str(val))
                    if mode=="=":
                        current.value=newvalue
                    elif mode=="*":
                        current.value *= newvalue
                    elif mode=="/":
                        current.value /= newvalue
                    elif mode=="+":
                        current.value += newvalue
                    elif mode=="-":
                        current.value -= newvalue
                    continue
                elif isinstance(current,MaterialProperties):
                    from ..materials.generic import Mixture,get_pure_material,get_pure_liquid,get_pure_gas,get_surfactant,get_interface_properties,get_pure_solid #type:ignore
                    try:
                        newvalue = eval(val)
                    except Exception as e:
                        raise RuntimeError("Cannot set the material " + varname + " to " + str(val) + "\n" + str(e))
                    if mode!="=":
                        raise RuntimeError("Cannot set material properties with e.g. +=, *=, -=, /=")
                elif isinstance(current,(list,tuple)):
                    try:
                        newvalue=eval(val)
                    except Exception as e:
                        raise RuntimeError("Cannot set the list " + varname + " to " + str(val) + "\n" + str(e))
                else:
                    raise RuntimeError("Implement setting parameter of type "+str(type(current))+" value="+str(current)) #type:ignore
                if isinstance(obj,dict):
                    if mode=="=":
                        obj[splt_varname[-1]]= newvalue
                    elif mode=="*":
                        obj[splt_varname[-1]]*= newvalue
                    elif mode=="/":
                        obj[splt_varname[-1]]/= newvalue
                    elif mode=="-":
                        obj[splt_varname[-1]]-= newvalue
                    elif mode=="+":
                        obj[splt_varname[-1]]+= newvalue
                else:
                    if mode=="=":
                        setattr(obj, splt_varname[-1], newvalue)
                    else:
                        old=getattr(obj,splt_varname[-1])
                        if mode=="*":
                            setattr(obj, splt_varname[-1], old*newvalue)
                        elif mode=="/":
                            setattr(obj, splt_varname[-1], old/ newvalue)
                        elif mode=="+":
                            setattr(obj, splt_varname[-1], old + newvalue)
                        elif mode=="-":
                            setattr(obj, splt_varname[-1], old - newvalue)
                if not self.is_quiet():
                    print("PARAMETER ", varname, "SET TO",newvalue)

    def before_assigning_equation_numbers(self,dof_selector:Optional["_DofSelector"]):
        self._equation_system._before_assigning_equations(dof_selector) 


    def actions_before_remeshing(self,active_remeshers:List["RemesherBase"]):
        pass



    def actions_after_change_in_global_parameter(self,param:str):
        pass

    def actions_after_parameter_increase(self,param:str):
        pass

    def actions_after_remeshing(self):
        self._equation_system._after_remeshing() 
        self.reapply_boundary_conditions()
        self.invalidate_cached_mesh_data()
        if self._custom_assembler:
            self._custom_assembler.actions_after_remeshing()


    def actions_before_newton_solve(self):
        self._domains_to_remesh.clear()
        for ism in range(self.nsub_mesh()):
            submesh=self.mesh_pt(ism)
            if isinstance(submesh,(MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d,InterfaceMesh,ODEStorageMesh)):
                #print("DIRCHLET UPDATE ",submesh,submesh.get_full_name())
                submesh.setup_Dirichlet_conditions(True)
        self._equation_system._before_newton_solve() 

    def actions_after_newton_solve(self):
        last_res=self.get_last_residual_convergence()
        if len(last_res)==0 or last_res[-1]>self.newton_solver_tolerance:
            return # Don't do this if it has not converged
        self._equation_system._after_newton_solve() 
        for ism in range(self.nsub_mesh()):
            submesh=self.mesh_pt(ism)
            if isinstance(submesh,MeshFromTemplateBase):
                submesh._solves_since_remesh+=1 
        if len(self._domains_to_remesh)>0:
            if (self._solve_in_arclength_conti is None) and self.do_call_remeshing_when_necessary:
                self.force_remesh(self._domains_to_remesh)
        self.invalidate_cached_mesh_data()
        if self._custom_assembler:
            self._custom_assembler.actions_after_succesfull_newton_solve()

    def remeshing_necessary(self):        
        """
        Checks whether any RemeshWhen object indicates that remeshing should be done.

        Returns:
            bool: True if remeshing would be required, False otherwise.
        """
        if len(self._domains_to_remesh)>0:
            return True
        return False

    def remesh_if_necessary(self) -> bool:
        """
        Invokes remeshing if one RemeshWhen object indicates that.

        Returns:
            bool: True if remeshing was performed, False otherwise.
        """
        res=False
        if len(self._domains_to_remesh)>0:
            self.force_remesh(self._domains_to_remesh)
            res=True
        return res
    

    # Can be used for go_to_param or 
    def remesh_handler_during_continuation(self, force: bool = False, resolve: bool = True, resolve_before_eigen: bool = False, reactivate_biftrack_neigen: int = 4,resolve_max_newton_steps : Optional[int]=None):
        """
        Handle remeshing during continuation. We might have to calculate e.g. a new eigenvector when doing bifurcation tracking.
        In that case, set Problem.do_remeshing_when_necessary to False to prevent any automatic remeshing.

        Args:
            force (bool, optional): Force remeshing even if not necessary. Defaults to False.
            resolve (bool, optional): Resolve the problem after remeshing. Defaults to True.
            resolve_before_eigen (bool, optional): Resolve the problem before solving the eigenproblem. Defaults to False.
            reactivate_biftrack_neigen (int, optional): Number of eigenvalues to reactivate bifurcation tracking. Defaults to 4.
            resolve_max_newton_steps (int, optional): Maximum number of Newton steps to resolve the problem. 

        Returns:
            bool: True if remeshing was performed, False otherwise.
        """
        if not force and not self.remeshing_necessary():
            return False
        biftrack = self.get_bifurcation_tracking_mode()
        biftrack_param = self._bifurcation_tracking_parameter_name
        if biftrack != "":
            self.reset_arc_length_parameters()
            self.deactivate_bifurcation_tracking()
            self.reset_arc_length_parameters()
        self.force_remesh()
        if biftrack != "":
            if resolve_before_eigen:
                self.actions_before_stationary_solve(force_reassign_eqs=True)
                self.solve(max_newton_iterations=resolve_max_newton_steps)
            self.solve_eigenproblem(reactivate_biftrack_neigen)
            self.activate_bifurcation_tracking(biftrack_param, biftrack)
            if resolve:
                self.solve(max_newton_iterations=resolve_max_newton_steps)
        elif resolve:
            self.solve(max_newton_iterations=resolve_max_newton_steps)

    def _link_geometry_and_equations(self):
        #Go through the templates and create them
        domset:Set[str]=set()
        for m in self._meshtemplate_list:
            m._do_define_geometry(self) 
            mydoms=set(m.available_domains())
            inters=domset.intersection(mydoms)
            if len(inters)>0:
                raise RuntimeError("Following domains are added multiple times: "+str(inters))
            domset.update(mydoms)


        if not hasattr(self,"_equation_system") or self._equation_system is None:
            raise RuntimeError("Please add at least one equation to the problem via add_equations()")

        self._equation_system._fill_dummy_equations(self)
        for m in self._meshtemplate_list:
            m._ensure_opposite_eq_tree_nodes(self._equation_system) 


        self._equation_system._finalize_equations(self) 
        for m in self._meshtemplate_list:
            m._connect_opposite_interfaces(self._equation_system) 
        self._equation_system._set_parent_to_equations(self) 

        #TODO: ODEs added to the root
        for meshname,eqtree in self._equation_system.get_children().items(): 
            #Find the mesh that generates the mesh we want to have
            if eqtree._equations is None: 
                raise RuntimeError("Empty bulk equations")
            mesh=None
            for m in self._meshtemplate_list:
                if m.has_domain(meshname):
                    mesh=MeshFromTemplate(self,m,meshname,eqtree)
                    self._meshdict[meshname]=mesh
                    assert eqtree._equations is not None
                    eqtree._equations._mesh=mesh  #type:ignore
            if eqtree._equations._is_ode(): 
                if mesh is not None:
                    if not isinstance(mesh,ODEStorageMesh):
                        raise RuntimeError("Cannot add an ODE to a spatial mesh yet")
                mesh=ODEStorageMesh(self,eqtree,meshname)
                eqtree.get_code_gen()._mesh=mesh 
                eqtree.get_code_gen().set_latex_printer(self.latex_printer)
                self._meshdict[meshname]=mesh
            else:
                if mesh is None:
                    print(str(self._equation_system))
                    raise RuntimeError("No mesh template with a domain named '"+meshname+'" was added, but there are equations defined on this domain')

        self._equation_system._create_dummy_domains_for_DG(self) 
        self._equation_system._finalize_equations(self,second_loop=True) 
        if not self.is_quiet():
            print("SOLVING THE FOLLOWING SYSTEM:\n"+str(self._equation_system))
        if self._outdir is not None:
            destpath = os.path.join(self._outdir, self._ccode_dir)
            Path(destpath).mkdir(parents=True, exist_ok=True)
            infofile=open(os.path.join(self.get_output_directory(),self._ccode_dir,"_equation_tree.txt"),"w")
            infofile.write(str(self._equation_system))
            infofile.close()

    def before_defining_problem(self,redefine:bool=False,old_meshes:Optional[Dict[str,AnyMesh]]=None,old_mesh_templates:Optional[List[MeshTemplate]]=None):
        pass

    def redefine_problem(self, code_dir:str,interpolator:Type["BaseMeshToMeshInterpolator"]=_DefaultInterpolatorClass,num_adapt:Optional[int]=None):
        """
        Redefines the problem by recompiling equations. 
        This can in principle be used if problem parameters have changed, but it is not recommended to change the problem structure.
        If possible, it is advised to use the global parameter system to change any parameters.

        Args:
            code_dir: Subdirectory in the output directory where the C++ code of the redefined problem will be written.
            interpolator: Mesh interpolator to map the fields of the old meshes to the new ones.
            num_adapt: Number of adaption steps after redefining the problem. If None, the number of adaption steps is determined by the max_refinement_level attribute.

        Raises:
            RuntimeError: If the problem contains no equations after the redefinition
        """
        self._ccode_dir = code_dir

        if not self.is_initialised():
            self.initialise()
            return

        self._equation_system = None #type:ignore
        old_meshtemplate_list = self._meshtemplate_list
        old_mesh_dict = self._meshdict
        self._meshtemplate_list = []
        self._meshdict = {}
        self.before_defining_problem(redefine=True, old_meshes=old_mesh_dict, old_mesh_templates=old_meshtemplate_list)
        self.define_problem()
        if self.additional_equations != 0:
            self.add_equations(self.additional_equations)

        self._link_geometry_and_equations()

        if len(self._meshdict) == 0:
            raise RuntimeError("No mesh or ODE added to the problem, do it in the define_problem() method")

        self.compile_meshes()

        self.rebuild_global_mesh_from_list(rebuild=True)

        self.relink_external_data()

        self.setup_pinning()
        self.before_assigning_equation_numbers(self._dof_selector)
        self.reapply_boundary_conditions()

        if self.cmdlineargs.distribute:
            self.distribute()

        self.init_output(redefined=True)
        self.rebuild_global_mesh_from_list(rebuild=True)
        self.reapply_boundary_conditions()


        num_adapt = self.max_refinement_level if num_adapt is None else num_adapt

        interpolators:Dict[str,"BaseMeshToMeshInterpolator"]={}

        def perform_interpolation():
            for _, interp in interpolators.items():
                interp.interpolate()

        for name, newmesh in self._meshdict.items():
            if name in old_mesh_dict.keys():
                omesh=old_mesh_dict[name]
                if isinstance(newmesh,MeshFromTemplateBase) and isinstance(omesh,MeshFromTemplateBase):
                    interpolators[name]=interpolator(omesh,newmesh)
                elif isinstance(newmesh,ODEStorageMesh) and isinstance(omesh,ODEStorageMesh):
                    interpolators[name]=ODEInterpolator(omesh,newmesh)
                omesh.get_eqtree()._before_mesh_to_mesh_interpolation(interpolators[name])

        if num_adapt > 0:
            no_need_to_reassign = False
            for s in range(num_adapt):
                perform_interpolation()
                if not self.is_quiet():
                    print("Remeshing adaption:", s, "of", num_adapt)
                nref, nunref = self._adapt()
                if nref == 0 and nunref == 0:
                    no_need_to_reassign = True
                    break
            if num_adapt > 0 and not (no_need_to_reassign):
                self.map_nodes_on_macro_elements()
                perform_interpolation()
        else:
            self.map_nodes_on_macro_elements()
            perform_interpolation()

        # TODO: Unload unused DLLs

    def before_parsing_cmd_line(self):
        pass

    def initialise(self):
        """
        Initializes the problem by performing the necessary setup and initialization steps.
        If not done before, this method is automatically called by several methods, e.g. :py:meth:`solve`, :py:meth:`run` or :py:meth:`output`. 
        After initialization, you cannot change the problem anymore, except for global parameter values.

        Raises:
            RuntimeError: If the problem is already initialised or if a function that calls initialize is called during initialization.
        """
                    
        if self.is_initialised():
            raise RuntimeError("Is already initialised")
        if self._during_initialization:
            raise RuntimeError("During initialization, you have called a function that calls initialize...")
        self._during_initialization=True

        self.setup_cmd_line()
        self.before_parsing_cmd_line()
        self.parse_cmd_line()
        if not self.is_quiet():
            print("OUTPUT WILL BE WRITTEN TO",self._outdir)
        if self._outdir is not None:
            Path(self._outdir).mkdir(parents=True, exist_ok=True)
            keyfile=os.path.join(self._outdir,"_pyoomph_run_.txt")
        else:
            keyfile=None

        if self._runmode=="continue":
            # Find the highest dump
            dumpdir = os.path.join(self.get_output_directory(), "_states")
            dumps = sorted(glob.glob(os.path.join(dumpdir, "*.dump")))
            if len(dumps)==0 or keyfile is None or not os.path.isfile(keyfile):
                print("Cannot continue, starting over")
                self._runmode="overwrite"
        elif self._runmode=="delete":
            if keyfile is not None and os.path.isfile(keyfile) and get_mpi_rank()<=0:
                if not self.is_quiet():
                    print("Removing contents of output dir")

                    def rem_subdir(subdir:str,filter:Union[str,List[str],Tuple[str]],remglob:Optional[Iterable[str]]=None):
                        top=os.path.join(self._outdir,subdir)
                        if not os.path.exists(top) or not os.path.isdir(top):
                            return
                        if not isinstance(filter,(list,tuple)):
                            filter=[filter]
                        lst:List[str]=[]
                        for g in filter:
                            glb=glob.glob(os.path.join(top,g))
                            if remglob:
                                for rg in remglob:
                                    glb=list(set(glb)-set(glob.glob(os.path.join(top,rg))))
                                #print("GLOB AFTER REMBLOG",glb,rg)
                            lst+=glb
                        for f in lst:
                            if os.path.isfile(f):
                                os.remove(f)
                                #print("REM",f)
                        #if not os.listdir(top):
                        #	os.rmdir(top)
                    if not self._suppress_code_writing:
                        rem_subdir("_ccode",["*.c","*.dll","*.o",".dylib","*.so"])
                    rem_subdir("_states", ["*.dump"])
                    rem_subdir("_plots", ["*.*"])

                    #rem_subdir(".", ["*.txt","*.pvd","*.mat"])
                    subdirs=[f.parts[-1] for f in Path(self._outdir).iterdir() if f.is_dir()]
                    remglob:Optional[List[str]]=None
                    if self._suppress_code_writing:
                        remglob=["*.c"]
                    if self._suppress_compilation:
                        if remglob is None:
                            remglob=[]
                        remglob+=["*.c","*.dll","*.o",".dylib","*.so"]
                    for s in subdirs:
                        rem_subdir(s,["*"],remglob)

        mpi_barrier()

        if get_mpi_rank()<=0 and keyfile is not None:
            f=open(keyfile,"w+")
            #TODO: Add information
            f.close()

        mpi_barrier()

        self.before_defining_problem()
        self.define_problem()
        if self._setup_azimuthal_stability_code:
            self.define_problem_for_axial_symmetry_breaking_investigation()
        if self.additional_equations != 0:
            self.add_equations(self.additional_equations)


        self._link_geometry_and_equations()

        if len(self._meshdict)==0:
            raise RuntimeError("No mesh or ODE added to the problem, do it in the define_problem() method")

        self.compile_meshes()
        #print("MESH COMPILE DONE")

        infofile = open(os.path.join(self.get_output_directory(), "_numerical_factors.txt"), "w")
        infofile.write(self._equation_system.numerical_factors_to_string())
        infofile.close()

        if self.latex_printer is not None:
#            raise RuntimeError("LATEX PRINTER")
            self.latex_printer.write_to_file(os.path.join(self.get_output_directory(), "system_info.tex"))


        self.rebuild_global_mesh_from_list(rebuild=False)

        self.relink_external_data()


        self.setup_pinning()
        self.before_assigning_equation_numbers(self._dof_selector)
        self.reapply_boundary_conditions()


        if self.cmdlineargs.distribute:
            self.distribute()

        if self._runmode!="continue" and self._runmode!="replot":
            if self.initial_adaption_steps is None:
                self.initial_adaption_steps=self.max_refinement_level
            if  (self.initial_adaption_steps>0):
                no_need_to_reassign=False
                for s in range(self.initial_adaption_steps):
                    self.map_nodes_on_macro_elements()
                    self.set_initial_condition()
                    self._initialised = True
                    self._during_initialization=False
                    if not self.is_quiet():
                        print("Initial adaption:",s,"of",self.initial_adaption_steps)
                    nref,nunref=self._adapt()
                    if nref==0 and nunref==0:
                        no_need_to_reassign=True
                        break
                if self.initial_adaption_steps>0 and not (no_need_to_reassign):
                    self.map_nodes_on_macro_elements()
                    self.set_initial_condition()
            else:
                self.map_nodes_on_macro_elements()
                self.set_initial_condition()
        else:
            self._initialised=True
            self._during_initialization=False

        if self.remove_macro_elements_after_initial_adaption:
            self.remove_macro_elements(self.remove_macro_elements_after_initial_adaption)

        if self._runmode=="replot":
            self._perform_replot()
            self.release()
            exit()

        if self._runmode=="continue":
            # Find the highest dump
            dumpdir=os.path.join(self.get_output_directory(),"_states")
            dumps=sorted(glob.glob(os.path.join(dumpdir,"*.dump")))
            while len(dumps)>0:
                dump_to_load=dumps.pop()
                if not self.is_quiet():
                    print("Loading state "+dump_to_load)
                try:
                    self._initialised = True
                    self._during_initialization=False
                    self.load_state(dump_to_load)
                    #self.save_state("_states/_continued_at_.dmp",relative_to_output=True)
                    break
                except Exception as e:
                    print("Cannot load state"+dump_to_load,e)
            else:
                raise RuntimeError("Cannot load any state file to continue")
            self._continue_initialized=True
            self._output_step+=1

        self._initialised = True
        self._during_initialization=False
        self.init_output()
        self.rebuild_global_mesh_from_list(rebuild=True)
        self.reapply_boundary_conditions()

        if self._custom_assembler:
            self._custom_assembler.initialize()

        if not self.is_quiet():
            print("PROBLEM IS NOW INITIALIZED")
            print("Following solvers will be used:")
            print("    Sparse Matrix Inversion: "+self.get_la_solver().idname)
            print("   Generalized Eigen Solver: "+self.get_eigen_solver().idname)       
            compiler_name="internal TCC compiler" 
            ccomp=self.get_ccompiler()
            if isinstance(ccomp,BaseCCompiler):
                compiler_name=ccomp.compiler_id
            print("  Equation code compiled by: "+ compiler_name)
            print("==========================")

        if self.plot_in_dedicated_process:
            if not self.write_states:
                raise RuntimeError("Cannot use 'plot_in_dedicated_process' without 'write_states'")
            try:
                mycmd=sys.orig_argv.copy()
            except:
                raise RuntimeError("Problem.plot_in_dedicated_process=True only works for Python>=3.10")
            mycmd+=["--runmode","p","--where","__pipe__"]
            plotlog=open(self.get_output_directory("_dedicated_plotter_log.txt"),"w")
            #self._plotting_process=subprocess.Popen(mycmd,stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE)
            if not self.is_quiet():
                print("Creating dedicated plot process: "+str(mycmd))
            self._plotting_process=subprocess.Popen(mycmd,stdin=subprocess.PIPE,stdout=plotlog,stderr=plotlog)
            #print(self._plotting_process.)



    def _perform_replot(self):
        if self._where_expression=="__pipe__":
            print("LISTENING FOR PLOTTING STATES..., __exit__ to close")
            for cmd in sys.stdin:
                cmd=cmd.rstrip()
                if cmd=="__exit__":
                    break
                else:
                    self.load_state(cmd)
                    self.timestepper.set_weights()
                    self.perform_plot()
        else:
            dumpdir = os.path.join(self.get_output_directory(), "_states")
            dumps = sorted(glob.glob(os.path.join(dumpdir, "*.dump")))
            for d in dumps:
                time,step=self._get_time_of_state_file(d)
                where_res=eval(self._where_expression,{},{"step":step,"time":time})
                #print(d,where_res)
                if where_res:
                    self.load_state(d)
                    self.timestepper.set_weights()
                    self.perform_plot()


    def rebuild_global_mesh_from_list(self,rebuild:bool=True):
        def recu_add_imeshes(sm:Union[MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d,InterfaceMesh]):
            for _k, im in sm._interfacemeshes.items():   # Interface meshes
                assert im._codegen is not None
                im._codegen._mesh = im 
                im.ensure_external_data() 
                self.add_sub_mesh(im) 
                self._interfacemeshes.append(im) 
            for _k, im in sm._interfacemeshes.items():   # Interface meshes
                recu_add_imeshes(im) 


        if rebuild:
            self.flush_sub_meshes()
            self._interfacemeshes=[]
        for _,m in self._meshdict.items():
            assert m._codegen is not None
            m._codegen._mesh=m 
            self.add_sub_mesh(m)
            if isinstance(m,(MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d)):
                recu_add_imeshes(m)
        if rebuild:
            if not self.is_quiet():
                print("REBUILDING GLOBAL MESH FROM LIST")
            self.rebuild_global_mesh()
        else:
            if not self.is_quiet():
                print("BUILDING GLOBAL MESH FROM LIST")
            self.build_global_mesh()
        for m in self._meshtemplate_list:
            m._connect_opposite_elements(self._equation_system) 



    def setup_pinning(self):
        self.ensure_dummy_values_to_be_dummy()
        for ism in range(self.nsub_mesh()):
            submesh=self.mesh_pt(ism)
            if isinstance(submesh,(MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d,InterfaceMesh,ODEStorageMesh)):
                #print("DIRCHLET SET ", submesh, submesh.get_full_name())
                submesh.setup_Dirichlet_conditions(False)
                assert submesh._codegen is not None 
                submesh._codegen.on_apply_boundary_conditions(submesh) 




    def set_initial_condition(self, ic_name: str = "", all_unset_dofs_to_zero: bool = False):
        """
        Set the initial condition for the problem.

        Args:
            ic_name (str, optional): Name of the initial condition. Multiple initial conditions can be defined in the problem definition by using the optional argument InitialConditions. Defaults to "".
            all_unset_dofs_to_zero (bool, optional): Flag indicating whether to set all unset degrees of freedom, i.e. without any InitialCondition with this ic_name, to zero. Defaults to False.
        """
        if all_unset_dofs_to_zero:
            self.set_current_dofs([0.0] * self.ndof())
        if not self.is_quiet():
            print("SETTING IC", ic_name)
        if self._runmode != "continue":
            for _, m in self._meshdict.items():
                m.setup_initial_conditions_with_interfaces(self._resetting_first_step, ic_name)
                if isinstance(m, ODEStorageMesh):
                    continue
                # for n, sm in m._interfacemeshes.items():
                #     sm.setup_initial_conditions()
                #     TODO Recursive
                #     print(sm)
                # print("ICMESH", m)
        self.setup_pinning()
        self.reapply_boundary_conditions()
        self.invalidate_cached_mesh_data()
        if self._custom_assembler:
            self._custom_assembler.actions_after_setting_initial_condition()



    def get_time_symbol(self,with_scaling:bool=True) -> Expression:
        return get_global_symbol("t")*(self.get_scaling("temporal") if with_scaling else 1)


    def actions_before_adapt(self):
        for m in self._interfacemeshes:
            m.clear_before_adapt()
            #print("CLEARED INTERFACE MESH",m.nelement())
        if len(self._interfacemeshes):
            if not self.is_quiet():
                print("REBUILDING GLOBAL MESH")
            self.rebuild_global_mesh()
        self.invalidate_cached_mesh_data()


    def actions_before_distribute(self):
        self.actions_before_adapt()
        for _, m in self._meshdict.items():
            if isinstance(m, ODEStorageMesh):
                continue
            m.ensure_halos_for_periodic_boundaries()

    def map_nodes_on_macro_elements(self):
        self.invalidate_cached_mesh_data()
        for _,m in self._meshdict.items():
            if isinstance(m,ODEStorageMesh):
                continue
            for ei in range(m.nelement()):
                elem=m.element_pt(ei)
                macro=elem.get_macro_element()
                if macro:
                    elem.map_nodes_on_macro_element()
        self._equation_system._after_mapping_on_macro_elements() 


    def remove_macro_elements(self,mode:Union[bool,Literal["auto"]]="auto"):        
        for _,m in self._meshdict.items():
            if isinstance(m,ODEStorageMesh):
                continue
            if mode=="auto" and m._codegen is not None and not m._codegen._coordinates_as_dofs: 
                continue

            for e in m.elements():
                e.set_macro_element(None,False)
                while  e.get_father_element() is not None:
                    e=e.get_father_element()
                    e.set_macro_element(None, False)

    def describe_equation(self,dofindex:int) -> str:
        res = "unknown(" + str(dofindex) + ")"
        for mesh_name, mesh in self._meshdict.items():
            if isinstance(mesh,ODEStorageMesh):
                continue
            for node in mesh.nodes():
                for vi in range(node.nvalue()):
                    eq = node.eqn_number(vi)
                    if eq == dofindex:
                        res="nodal value index "+str(vi)+ ". Node is located at " + ", ".join(map(str, [node.x(xi) for xi in range(node.ndim())]))+" in mesh "+mesh_name
                        break
                pd=node.variable_position_pt()
                for vi in range(pd.nvalue()):
                    eq=pd.eqn_number(vi)
                    if eq == dofindex:
                        res="nodal position index "+str(vi)+ ". Node is located at " + ", ".join(map(str, [node.x(xi) for xi in range(node.ndim())]))+" in mesh "+mesh_name
                        break

        for ism in range(self.nsub_mesh()):
            sm=self.mesh_pt(ism)
            assert isinstance(sm,(MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d,InterfaceMesh,ODEStorageMesh))
            for e in sm.elements():
                for di in range(e.ndof()):
                    eq=e.eqn_number(di)
                    if eq==dofindex:
                        dn=e.get_dof_names()
                        res=res+"\n"+"Found in element of submesh "+sm.get_name()+" elem internal:"+str(e.ninternal_data())+" external:"+str(e.nexternal_data())+" dofname: "+dn[di]
                        break
        return res


    def reapply_boundary_conditions(self):
        self.setup_pinning()
        self.before_assigning_equation_numbers(self._dof_selector)
        self._dof_selector_used=self._dof_selector
        neq=self.assign_eqn_numbers(True)
        if not self.is_quiet():
            print("Number of equations: " + str(neq))
        if self._custom_assembler:
            self._custom_assembler.actions_after_equation_numbering()

    def get_dof_description(self):
        """
        Returns two arrays containing the description of the degrees of freedom.
        The first is a list of dof-type indices, where the i-th entry is the type of the i-th degree of freedom.
        To resolve what each dof-type index means, the second array contains the type names of the degrees of freedom.
        
        For a simple Poisson equation for a field ``u`` on a line domain name ``"domain"``, the first returned array will contain numbers between 0 and 2 (dof-type indices), and the second array will contain the type names ``["domain/u", "domain/left/u", "domain/right/u"]``.
        Note how the boundaries get their own dof-type indices.
                        
        Returns:
            A pair of arrays containing the dof-type indices and the type names to classify the degrees of freedom.
        """
        doflist:NPIntArray=numpy.array([],dtype=numpy.int32) #type:ignore
        dofnames:List[str] = []

        def process(m:AnyMesh):
            nonlocal doflist,dofnames
            types, names = m.describe_global_dofs()
            types=numpy.array(types) #type:ignore
            #if numpy.all(types<0):
            #	print("MESH "+m.get_full_name()+" does not identify any dofs...")
            #print(m.get_full_name(),types,names)
            if len(doflist)==0:
                doflist = numpy.array(types,dtype=numpy.int32) #type:ignore
            offset = len(dofnames)
            trunk = m.get_full_name()
            for n in names:
                dofnames.append(trunk + "/" + n)
            for k in range(len(doflist)):
                if k>=len(types):
                    raise RuntimeError("Strange. Should not happen: "+m.get_full_name()+" NAMES: "+str(names)+" TYPES: "+str(types),"DOFLIST: "+str(doflist))
                if types[k] >= 0:
                    doflist[k] = offset + types[k]
            if not isinstance(m,ODEStorageMesh):
                for im in m._interfacemeshes.values(): 
                    process(im)

        for _, bm in self._meshdict.items():
            process(bm)

        if numpy.any(doflist<0): #type:ignore
            print("UNASSIGNED DOF IN DOFLIST")
            print("NUM:",len(numpy.argwhere(doflist<0)),"of",len(doflist)) #type:ignore

        return doflist, dofnames


    def search_dof_in_mesh(self,mesh:AnyMesh,dofindex:int):
        location = None
        typ = None
        if not isinstance(mesh,ODEStorageMesh):
            for n in mesh.nodes():
                found_in_node = False
                for iv in range(n.nvalue()):
                    if n.eqn_number(iv) == dofindex:
                        found_in_node = True
                        break
                if not found_in_node:
                    for ip in range(n.ndim()):
                        if n.variable_position_pt().eqn_number(ip) == dofindex:
                            found_in_node = True
                            break
                if found_in_node:
                    location = [n.x(i) for i in range(n.ndim())]
                    if n.is_on_boundary():
                        typ = "boundary node"
                        bn = mesh.get_boundary_names()
                        onbounds:List[str] = []
                        for i in range(len(bn)):
                            if n.is_on_boundary(i):
                                onbounds.append(bn[i])
                        if len(onbounds) > 0:
                            typ += " (" + ", ".join(onbounds) + ")"
                        else:
                            typ += " (NO BOUND NAMES FOUND)"
                    else:
                        typ = "bulk node"
                    break
        if location is None:
            for e in mesh.elements():
                for nid in range(e.ninternal_data()):
                    id = e.internal_data_pt(nid)
                    for vid in range(id.nvalue()):
                        if id.eqn_number(vid) == dofindex:
                            location = e.get_Eulerian_midpoint()
                            typ = "element"
                            break
        if location is None:
            for e in mesh.elements():
                for nid in range(e.nexternal_data()):
                    id = e.external_data_pt(nid)
                    for vid in range(id.nvalue()):
                        if id.eqn_number(vid) == dofindex:
                            location = e.get_Eulerian_midpoint()
                            typ = "data stored in other element"
                            break

        return location,typ

    def debug_largest_residual(self, nres:int=4):
        descr, names = self.get_dof_description()
        #print(names)
        #print(descr)
        res_vect:NPFloatArray = numpy.array(self.get_residuals()) #type:ignore
        highdofsI:NPIntArray = numpy.argsort(numpy.absolute(res_vect)) #type:ignore
        highdofs:List[int] = list(reversed(highdofsI[-1 - nres+1:])) #type:ignore
        print("========MAX. RESIDUALS========")
        for idof, dofindex in enumerate(highdofs):
            print("Highest residual", idof + 1, " with a value of", res_vect[dofindex], "Eqn number:", dofindex)
            if descr[dofindex] >= 0:
                dofstr:str = names[descr[dofindex]]
                print("   belongs to " + dofstr)
                # Find the dof
                splt = dofstr.split("/")
                meshname = "/".join(splt[0:-1])
                #dofname = splt[-1]
                mesh = self.get_mesh(meshname, return_None_if_not_found=True)
                if mesh is not None:
                    location,typ=self.search_dof_in_mesh(mesh,dofindex)
                    if location is None or typ is None:
                        print("   ... cannot find any node or element containing this dof...")
                    else:
                        print("   found at " + str(location) + ". Type: " + typ)
                else:
                    print("   cannot find the mesh " + meshname)
            else:
                print("   cannot find a description...")
                for ism in range(self.nsub_mesh()):
                    mesh=self.mesh_pt(ism)
                    assert isinstance(mesh,(MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d,InterfaceMesh,ODEStorageMesh))
                    location, typ = self.search_dof_in_mesh(mesh, dofindex)
                    if location is not None and typ is not None:
                        print("     but found in mesh "+mesh.get_full_name()+" at " + str(location) + ". Type: " + typ)
                    else:
                        print(" 		not found in mesh "+mesh.get_full_name())
                    #print("DESCRIBE",self.describe_equation(dofindex))
                    for e in mesh.elements():
                        for d in range(e.ndof()):
                            if e.eqn_number(d)==dofindex:
                                print("				FOUND IN ELEMENT at "+str(e.get_Eulerian_midpoint())+" nnode "+str(e.nnode())+" ninternal "+str(e.ninternal_data())+" nexternal "+str(e.nexternal_data()))
                                for ni in range(e.nnode()):
                                    en=e.node_pt(ni)
                                    for nv in range(en.nvalue()):
                                        if en.eqn_number(nv)==dofindex:
                                            print("             FOUND AT ELEMENTAL NODE AT INDEX "+str(ni)+", "+str(nv)+ " located at "+str([en.x(pi) for pi in range(en.ndim()) ]))
                                        else:
                                            print("                   nonmatching nodal "+str(ni)+", "+str(nv)+"  "+str(en.eqn_number(nv)))
                                for ne in range(e.ninternal_data()):
                                    id=e.internal_data_pt(ne)
                                    for nv in range(id.nvalue()):
                                        if id.eqn_number(nv)==dofindex:
                                            print("             FOUND AT INTERNAL DATA AT INDEX "+str(ne)+", "+str(nv))
                                for ne in range(e.nexternal_data()):
                                    id=e.external_data_pt(ne)
                                    for nv in range(id.nvalue()):
                                        if id.eqn_number(nv)==dofindex:
                                            print("             FOUND AT EXTERNAL DATA AT INDEX "+str(ne)+", "+str(nv))
        print("=====END OF MAX. RESIDUALS======")
        print()

    def actions_before_newton_convergence_check(self)->None:
        accept_step=self._equation_system._before_newton_convergence_check() 
        if not accept_step:
            print("Invalidating step by filling the dof vector with random exteme values")
            dofs,_=self.get_current_dofs()
            dofs=numpy.array(dofs)
            dofs[:]=1e40*dofs[:]+numpy.random.rand(len(dofs))*1e40
            self.set_current_dofs(dofs)            

    def actions_after_newton_step(self):
        #if self._solve_in_arclength_conti is not None:
        #    self.actions_after_change_in_global_parameter(self._solve_in_arclength_conti)
        if self._debug_largest_residual>0:
            self.debug_largest_residual(self._debug_largest_residual)
        if self.get_bifurcation_tracking_mode()!="" and not self.is_quiet():
            paramnames=[pn for pn in self.get_global_parameter_names() if not pn.startswith("_")]            
            if len(paramnames)>0:
                paramstr="Currently at parameters: "+", ".join([n+"="+str(self.get_global_parameter(n).value) for n in paramnames])
                print(paramstr)

    def actions_after_adapt(self):
        for m in self._interfacemeshes:
            m.rebuild_after_adapt()
            m.ensure_external_data()
            #print("REBUILD INTERFACE MESH",m,m.get_name(), m.nelement(),m.element_pt(0))
        if not self.is_quiet():
            print("REBUILDING GLOBAL MESH")
        self.rebuild_global_mesh()
        for m in self._meshtemplate_list:
            m._connect_opposite_elements(self._equation_system)
        self.setup_pinning()
        self.reapply_boundary_conditions()
        if self._call_output_after_adapt:
            self.output()
        if self._custom_assembler:
            self._custom_assembler.actions_after_adapt()


    def compile_bulk_element_code(self,elementtype:FiniteElementCodeGenerator,bulkmesh:AnyMesh,subname:str) -> _pyoomph.DynamicBulkElementInstance:
        if self._outdir is not None:
            destpath=os.path.join(self._outdir,self._ccode_dir)
            Path(destpath).mkdir(parents=True, exist_ok=True)
            trunk=os.path.join(destpath,subname)
        else:
            trunk=""
        suppress_compilation=False
        suppress_writing=False
        if self._suppress_compilation or get_mpi_rank()>0:
            ccomp=self.get_ccompiler()
            if not ccomp.compiling_to_memory():
                suppress_compilation=True
        if self._suppress_code_writing or get_mpi_rank()>0:
            suppress_writing=True
        mpi_barrier()
        res=self.generate_and_compile_bulk_element_code(elementtype,trunk,suppress_writing,suppress_compilation,bulkmesh,self.is_quiet(),self.extra_compiler_flags)
        #print("REt")
        mpi_barrier()
        #print("REt MPI")
        self._bulk_element_code_counter=self._bulk_element_code_counter+1
        return res


    def set_current_time(self, val: ExpressionOrNum, dimensional: bool = True, as_float: bool = False):
        """
        Set the current time of the problem.

        Args:
            val (ExpressionOrNum): The value of the time to set.
            dimensional (bool, optional): Flag indicating whether the time is dimensional or not. Defaults to True.
            as_float (bool, optional): Flag indicating whether to convert the time to a float. Defaults to False.

        Raises:
            ValueError: If the nondimensional time is not a number.
            ValueError: If the dimensional time cannot be nondimensionalized.

        Returns:
            None
        """
        tp = self.time_pt()
        if not dimensional:
            if not (isinstance(val, int) or isinstance(val, float)):
                raise ValueError("Nondimensional time needs to be a number, not " + str(val))
            tp.set_time(val)
        else:
            ts = self.get_scaling("temporal")
            t = val / ts
            if as_float:
                if isinstance(t, _pyoomph.Expression):
                    tin = t
                else:
                    tin = _pyoomph.Expression(t)
                factor, _, _, _ = _pyoomph.GiNaC_collect_units(tin)
                t = float(factor)
            else:
                try:
                    t = float(t)
                except:
                    raise ValueError("Cannot nondimensionalise time " + str(val) + " with time scale " + str(ts))
            tp.set_time(t)
    

    def define_global_parameter(self, **params: float) -> Union[_pyoomph.GiNaC_GlobalParam, Tuple[_pyoomph.GiNaC_GlobalParam, ...]]:
        """
        Define one or more global parameters for the problem.

        Args:
            **params: A dictionary of parameter names and their corresponding initial values.

        Returns:
            Union[_pyoomph.GiNaC_GlobalParam, Tuple[_pyoomph.GiNaC_GlobalParam, ...]]: 
            The defined global parameter(s), which can be used in expressions.

        """
        res = []
        for p, v in params.items():
            res.append(self.get_global_parameter(p))
            res[-1].value = v
        if len(res) == 1:
            return res[0]
        else:
            return tuple([*res])
        
    def setup_for_stability_analysis(self,analytic_hessian:bool=True,use_hessian_symmetry:bool=True,improve_pitchfork_on_unstructured_mesh:bool=False,improve_pitchfork_coordsys:"OptionalCoordinateSystem"=None,improve_pitchfork_position_coordsys:"OptionalCoordinateSystem"=None,shared_shapes_for_multi_assemble:Optional[bool]=None,azimuthal_stability:Optional[bool]=None):
        """
        Sets up the problem for stability analysis, e.g. for improved pitchfork tracking on unsymmetric meshes, azimuthal stability, etc.
        Arguments which are None are not changed.

        Args:
            analytic_hessian (bool, optional): Flag indicating whether to use an analytically derived symbolical Hessian. Defaults to True.
            use_hessian_symmetry (bool, optional): Flag indicating whether to use symmetry in the Hessian. Defaults to True.
            improve_pitchfork_on_unstructured_mesh (bool, optional): Flag indicating whether to improve pitchfork tracking on unsymmetric meshes. Defaults to False.
            improve_pitchfork_coordsys (OptionalCoordinateSystem, optional): Coordinate system for improving pitchfork tracking unsymmetric meshes. Defaults to None.
            improve_pitchfork_position_coordsys (OptionalCoordinateSystem, optional): Coordinate system for improving pitchfork position space. Defaults to None.
            shared_shapes_for_multi_assemble (Optional[bool], optional): Flag indicating whether to use shared shapes for multi-assemble. Defaults to None.
            azimuthal_stability (Optional[bool], optional): Flag indicating whether to set up azimuthal stability code. Defaults to None.
        """            
        if analytic_hessian:
            # May not use symmetric Hessian for azimuthal stability
            self.set_analytic_hessian_products(True,use_hessian_symmetry and not azimuthal_stability)
        else:
            self.set_analytic_hessian_products(False)
        #if azimuthal_stability:
        #    self.set_analytic_hessian_products(False) # We may not use it here!
        if improve_pitchfork_on_unstructured_mesh:
            self.improve_pitchfork_tracking_on_unstructured_meshes(coord_sys=improve_pitchfork_coordsys,pos_coord_sys=improve_pitchfork_position_coordsys)
        if shared_shapes_for_multi_assemble is not None:
            self._shared_shapes_for_multi_assemble=shared_shapes_for_multi_assemble
        if azimuthal_stability:
            self._setup_azimuthal_stability_code=azimuthal_stability



    @overload
    def get_current_time(self,dimensional:bool=...,as_float:Literal[False]=...)->Expression: ...

    @overload
    def get_current_time(self,dimensional:bool=...,as_float:Literal[True]=...)->float: ...

    def get_current_time(self, dimensional: bool = True, as_float: bool = False) -> ExpressionOrNum:
        """
        Get the current time of the problem.

        Args:
            dimensional (bool, optional): Flag indicating whether to return the dimensional time. Defaults to True.
            as_float (bool, optional): Flag indicating whether to return the time as a float. Defaults to False.

        Returns:
            ExpressionOrNum: The current time of the problem.

        Raises:
            ValueError: If the problem is not initialized.

        """
        if not self.is_initialised():
            self.initialise()
        t = self.time_pt().time()
        if not dimensional:
            return t
        ts = self.get_scaling("temporal")
        t = t * ts
        if not as_float:
            return t
        try:
            t = float(t)
        except:
            t = float(t / second)
        return t

    def process_eigenvectors(self,eigenvectors:NPFloatArray):
        """Here, you can optionally scale or negate the eigenvectors, e.g. normalize them, by overriding this method

        Args:
            eigenvectors (NPFloatArray): 2d array of eigenvectors

        Returns:
            NPFloatArray: Processed array of eigenvectors
        """
        # 
        return eigenvectors

    def solve_eigenproblem(self, n:int, shift:Union[float,complex,None]=0, quiet:bool=False, azimuthal_m:Optional[Union[int,List[int]]]=None,report_accuracy:bool=False,sort:bool=True,which:"EigenSolverWhich"="LM",OPpart:Optional[Literal["r","i"]]=None,v0:Optional[Union[NPFloatArray,NPComplexArray]]=None,filter:Optional[Callable[[complex],bool]]=None,target:Optional[complex]=None)->Tuple[NPComplexArray,NPComplexArray]:
        """
        Solves the associated generalized eigenproblem for the given number of eigenvalues and eigenvectors.

        Args:
            n (int): The number of eigenvalues and eigenvectors to compute.
            shift (Union[float, complex, None], optional): The shift applied for shift-inverted approaches to solve the eigenproblem. Defaults to 0.
            quiet (bool, optional): If True, suppresses the output. Defaults to False.
            azimuthal_m (Optional[Union[int, List[int]]], optional): The azimuthal mode number(s) for axial symmetry breaking. Defaults to None, i.e. the axisymmetric mode.
            report_accuracy (bool, optional): If True, reports the accuracy of the computed eigenvalues. Defaults to False.
            sort (bool, optional): If True, sorts the eigenvalues in ascending order. Defaults to True.
            which ("EigenSolverWhich", optional): The type of eigenvalues to compute. Defaults to "LM".
            OPpart (Optional[Literal["r", "i"]], optional): The part of the operator to use. Defaults to None.
            v0 (Optional[Union[NPFloatArray, NPComplexArray]], optional): The initial guess for the eigenvectors. Defaults to None.
            filter (Optional[Callable[[complex], bool]], optional): A function to filter the computed eigenvalues. Only the eigenvalues for which the filter returns True will be kept. Defaults to None.
            target (Optional[complex], optional): The target eigenvalue. Defaults to None.

        Returns:
            Tuple[NPComplexArray, NPComplexArray]: A tuple containing the computed eigenvalues and eigenvectors.
        """
        if not self.is_initialised():
            self.initialise()
        if azimuthal_m is not None:
            return self.solve_axial_symmetry_breaking_eigenproblem(n, azimuthal_m, shift, quiet,filter=filter,report_accuracy=report_accuracy)
        if self._dof_selector_used is not self._dof_selector:
            self.reapply_boundary_conditions()
        if self.get_bifurcation_tracking_mode()!="":
            raise RuntimeError("Cannot calculate eigenvalues/vectors when bifurcation tracking is active. You can access the critical eigenvector(s) by get_last_eigenvectors()")
        ntstep=self.ntime_stepper()
        was_steady=[False]*ntstep
        for i in range(ntstep):
            ts=self.time_stepper_pt(i)
            was_steady[i]=ts.is_steady()
            ts.make_steady()
        self.actions_before_eigen_solve()
        self.invalidate_cached_mesh_data(only_eigens=True)
        self.setup_forced_zero_dof_list_for_eigenproblems()
        self._last_eigenvalues,self._last_eigenvectors=self.get_eigen_solver().solve(n,shift=shift,sort=sort,which=which,OPpart=OPpart,v0=v0,target=target)
        self._last_eigenvalues, self._last_eigenvectors=self._last_eigenvalues.copy(),self._last_eigenvectors.copy()
        if filter is not None:
            filtered_indices=numpy.array([filter(ev) for ev in self._last_eigenvalues]).nonzero()
            self._last_eigenvalues=self._last_eigenvalues[filtered_indices]
            self._last_eigenvectors=self._last_eigenvectors[filtered_indices]

        self._last_eigenvectors=self.process_eigenvectors(self._last_eigenvectors)

        #self._last_eigenvectors=numpy.transpose(self._last_eigenvectors)
        if (not self.is_quiet()) and (not quiet) :
            if report_accuracy:                
                self.actions_before_eigen_solve()                
                self.setup_forced_zero_dof_list_for_eigenproblems()
                J,M,n,is_complex=self.get_eigen_solver().get_J_M_n_and_type()
                for i,l in enumerate(self._last_eigenvalues):
                    v=self._last_eigenvectors[i,:]
                    lhs =l*(M@v) #type:ignore
                    rhs=J@v #type:ignore
                    diff=lhs-rhs #type:ignore
                    abs_err=numpy.max(numpy.absolute(diff))
                    rel_err=abs_err/numpy.linalg.norm(v)
                    print("Eigenvalue",i,":",l,"Error (abs/rel):",abs_err,rel_err) #type:ignore
                pass
            else:
                for i,l in enumerate(self._last_eigenvalues):
                    print("Eigenvalue",i,":",l)
        for i in range(ntstep):
            if not was_steady[i]:
                self.time_stepper_pt(i).undo_make_steady()
        return self._last_eigenvalues,self._last_eigenvectors


    def _override_for_this_solve(self,*,max_newton_iterations:Optional[int]=None,newton_relaxation_factor:Optional[float]=None,newton_solver_tolerance:Optional[float]=None,globally_convergent_newton:Optional[bool]=None):
        old:Dict[str,Union[int,bool,float]]={}
        if max_newton_iterations is not None:
            old["max_newton_iterations"]=self.max_newton_iterations
            self.max_newton_iterations=max_newton_iterations
        if newton_relaxation_factor is not None:
            old["newton_relaxation_factor"]=self.newton_relaxation_factor
            self.newton_relaxation_factor=newton_relaxation_factor
        if newton_solver_tolerance is not None:
            old["newton_solver_tolerance"]=self.newton_solver_tolerance
            self.newton_solver_tolerance=newton_solver_tolerance
        if globally_convergent_newton is not None:
            old["globally_convergent_newton"]=False
            self._set_globally_convergent_newton_method(globally_convergent_newton)
        return old

    def set_arc_length_parameter(self,desired_proportion_of_arc_length:Optional[float]=None,scale_arc_length:Optional[bool]=None,use_FD:Optional[bool]=None,use_continuation_timestepper:Optional[bool]=None,Desired_newton_iterations_ds:Optional[int]=None):
        if desired_proportion_of_arc_length is not None:
            self._set_arclength_parameter("Desired_proportion_of_arc_length",desired_proportion_of_arc_length)
        if scale_arc_length is not None:
            self._set_arclength_parameter("Scale_arc_length",1 if scale_arc_length else 0)
        if use_FD is not None:
            self._set_arclength_parameter("Use_finite_differences_for_continuation_derivatives",1 if use_FD else 0)
        if use_continuation_timestepper is not None:
            self._set_arclength_parameter("Use_continuation_timestepper",1 if use_continuation_timestepper else 0)
        if Desired_newton_iterations_ds is not None:
            self._set_arclength_parameter("Desired_newton_iterations_ds",Desired_newton_iterations_ds)

    def arclength_continuation(self, parameter: Union[str, _pyoomph.GiNaC_GlobalParam], step: float, *,
                              spatial_adapt: int = 0, max_ds: Optional[float] = None,
                              max_newton_iterations: Optional[int] = None,
                              newton_relaxation_factor: Optional[float] = None,
                              newton_solver_tolerance: Optional[float] = None,
                              min_ds: Optional[float] = None, dof_direction: Optional[List[float]] = None,
                              globally_convergent_newton: Optional[bool] = False) -> float:
        """
        Perform arclength continuation on the basis of a given parameter.

        Args:
            parameter (Union[str, _pyoomph.GiNaC_GlobalParam]): The parameter to perform arclength continuation on.
            step (float): The step for the continuation.
            spatial_adapt (int, optional): The level of spatial adaptation. Defaults to 0.
            max_ds (float, optional): The maximum step size. Defaults to None.
            max_newton_iterations (int, optional): The maximum number of Newton iterations. Defaults to None.
            newton_relaxation_factor (float, optional): The relaxation factor for the Newton solver. Defaults to None.
            newton_solver_tolerance (float, optional): The tolerance for the Newton solver. Defaults to None.
            min_ds (float, optional): The minimum step size. Defaults to None.
            dof_direction (List[float], optional): The direction of degrees of freedom. Defaults to None.
            globally_convergent_newton (bool, optional): Whether to use globally convergent Newton solver. Defaults to False.

        Returns:
            float: The new step size for the continuation.
        """
        self._activate_solver_callback()
        self.invalidate_cached_mesh_data()
        if not self.is_initialised():
            self.initialise()
            self._activate_solver_callback()

        step = float(step)
        if max_ds is not None:
            max_ds = float(max_ds)

        if min_ds is not None:
            old_min_ds = self.minimum_arclength_ds
            self.minimum_arclength_ds = min_ds

        if isinstance(parameter, _pyoomph.GiNaC_GlobalParam):
            parameter = parameter.get_name()

        if self._last_arclength_parameter is not None:
            if self._last_arclength_parameter != parameter:
                self.reset_arc_length_parameters()
        self._last_arclength_parameter = parameter

        if not self.is_quiet():
            print("Continuation in parameter " + parameter + "=" + str(self.get_global_parameter(parameter).value) +
                  " with step " + str(step))
        oldsettings = self._override_for_this_solve(max_newton_iterations=max_newton_iterations,
                                                    newton_relaxation_factor=newton_relaxation_factor,
                                                    newton_solver_tolerance=newton_solver_tolerance,
                                                    globally_convergent_newton=globally_convergent_newton)
        if max_ds is not None:
            if abs(step) > abs(max_ds):
                step = abs(max_ds) * (1 if step > 0 else -1)
        if dof_direction is not None:
            self._set_dof_direction_arclength(dof_direction)  # does not really work

        self.invalidate_eigendata()

        self._solve_in_arclength_conti = parameter
        self.actions_before_stationary_solve()
        newds = self._arc_length_step(parameter, step, spatial_adapt)
        self._last_step_was_stationary = True
        self._solve_in_arclength_conti = None

        if self.get_bifurcation_tracking_mode() != "":
            self._last_eigenvalues = numpy.array([0 + self._get_bifurcation_omega() * 1j], dtype=numpy.complex128)  # type:ignore
            self._last_eigenvectors = numpy.array([self._get_bifurcation_eigenvector()], dtype=numpy.complex128)  # type:ignore
            self._last_eigenvectors = self.process_eigenvectors(self._last_eigenvectors)
            if self.get_bifurcation_tracking_mode() == "azimuthal":
                assert self._azimuthal_mode_param_m is not None
                self._last_eigenvalues_m = numpy.array([int(self._azimuthal_mode_param_m.value)], dtype=numpy.int32)  # type:ignore
            else:
                self._last_eigenvalues_m = None

        if not self.is_quiet():
            print("GETTING NEW DS ", newds, "PLANNED", step)
        self._override_for_this_solve(**oldsettings)
        if max_ds is not None:
            if abs(newds) > abs(max_ds):
                newds = abs(max_ds) * (1 if newds > 0 else -1)
        if not self.is_quiet():
            print("RETURNING NEW DS ", newds, "PLANNED", step)

        if min_ds is not None:
            self.minimum_arclength_ds = old_min_ds  # type:ignore
        return newds

    def go_to_param(self, *, reset_pars:bool=True, startstep:Optional[float]=None, call_after_step:Optional[Callable[[float],None]]=None,final_adaptive_solve:Union[bool,int]=False,max_newton_iterations:Optional[int]=None, **kwargs:float)->None:
        """
        Perform arclength continuation in a parameter until we reach the desired value.

        Args:
            reset_pars (bool, optional): Whether to reset arc length parameters. Defaults to True.
            startstep (float, optional): The initial step size for the parameter continuation. Defaults to None.
            call_after_step (Callable[[float],None], optional): A function to call after each step. Defaults to None.
            final_adaptive_solve (Union[bool,int], optional): Whether to perform a final adaptive solve. Defaults to False.
            max_newton_iterations (int, optional): The maximum number of Newton iterations. Defaults to None.
            **kwargs (float): The parameter name and desired value.

        Raises:
            RuntimeError: If more than one parameter is provided.
            RuntimeError: If the specified parameter is not part of the problem.

        Returns:
            None
        """
                        
        if len(kwargs) != 1:
            raise RuntimeError("Please to it with only one parameter!")
        pname:str=""
        desired_val:float=0.0
        for a, b in kwargs.items():
            pname = a
            desired_val = float(b)
        if pname not in self.get_global_parameter_names():
            raise RuntimeError("Cannot go to parameter "+str(pname)+"="+str(desired_val)+", since the parameter '"+str(pname)+"' is not part of the problem")
        if not self.is_initialised():
            self.initialise()

        if self._dof_selector_used is not self._dof_selector:
            self.reset_arc_length_parameters()
            self.reapply_boundary_conditions()


        ds = desired_val - self.get_global_parameter(pname).value

        if startstep is not None:
            dsold=ds
            ds = float(startstep)
            if dsold*ds<0:
                ds=-ds
            if abs(dsold)<abs(ds):
                ds=abs(dsold)*(-1 if ds<0 else 1)
        while abs(desired_val - self.get_global_parameter(pname).value) > 1e-6:
            ds = self.arclength_continuation(pname, ds, max_ds=desired_val - self.get_global_parameter(pname).value,max_newton_iterations=max_newton_iterations)
            #print("AFTER DS WE HAVE NEW DS",ds,"param deriv",self.get_arc_length_parameter_derivative())
            if reset_pars:
                self.reset_arc_length_parameters()
                if ds * (desired_val - self.get_global_parameter(pname).value) < 0:
                    ds *= -1  # Always move towards the parameter
            if call_after_step is not None:
                call_after_step(ds)
        self.get_global_parameter(pname).value = desired_val
        if self.max_refinement_level > 0 and final_adaptive_solve:
            if isinstance(final_adaptive_solve,bool) and final_adaptive_solve:
                self.solve(spatial_adapt=self.max_refinement_level,max_newton_iterations=max_newton_iterations)
            else:
                self.solve(spatial_adapt=final_adaptive_solve,max_newton_iterations=max_newton_iterations)


    def invalidate_eigendata(self):
        self._last_eigenvectors:NPComplexArray=numpy.array([],dtype=numpy.complex128) #type:ignore
        self._last_eigenvalues:NPComplexArray=numpy.array([],dtype=numpy.complex128) #type:ignore
        self._last_eigenvalues_m=None

    # Warning: This must be used with "for parameter, eigenvalue in find_bifurcation_via_eigenvalues(...):"
    def find_bifurcation_via_eigenvalues(self, parameter:Union[str,_pyoomph.GiNaC_GlobalParam], initstep:float, shift:Union[None,float,complex]=0, neigen:int=6, spatial_adapt:int=0, epsilon:float=1e-8, reset_arclength:bool=False, max_ds:Optional[Union[float,Callable[[float],float]]]=None, stay_stable_file:Optional[str]=None, before_eigensolving:Optional[Callable[[float],None]]=None, do_solve:bool=True, azimuthal_m:Optional[Union[int,List[int]]]=None, eigenindex:int=0):
        """
        Approximates a bifurcation point by bisecting on the basis of the eigenvalues.
        Must be called as a generator, e.g.

        .. code-block:: python        
        
            for parameter, eigenvalue in find_bifurcation_via_eigenvalues(...):
                print("Currently at ",parameter,eigenvalue)            

        Parameters:
				parameter (Union[str,_pyoomph.GiNaC_GlobalParam]): The parameter to vary to find a bifurcation. It can be either a string representing the name of a global parameter or a global parameter directly.
				initstep (float): The initial step size for the bisection.
				shift (Union[None,float,complex]): The shift value for the eigenvalue problem. It can be a float, complex number, or None.
				neigen (int): The number of eigenvalues to compute.
				spatial_adapt (int): The spatial adaptation level.
				epsilon (float): The tolerance for determining the real part of an eigenvalue to be close to zero.
				reset_arclength (bool): Whether to reset the arc length parameters after each step.
				max_ds (Optional[Union[float,Callable[[float],float]]]): The maximum step size for the continuation. It can be a float, a callable function that takes the current parameter value and returns a float, or None.
				stay_stable_file (str, optional): The file path to save the state when the solution is stable. If it is unstable, the state is reloaded.
				before_eigensolving (Optional[Callable[[float],None]]): A callable function to be called before solving the eigenvalue problem.
				do_solve (bool): Whether to solve the problem before continuation. If the solution does not depend on the parameter, it can be set to False.
				azimuthal_m (Optional[Union[int,List[int]]]): The azimuthal mode number if you want to find azimuthal perturbations.
				eigenindex (int): The index of the eigenvalue to track. Defaults to 0, i.e. the one with the largest real part.

        Yields:
				param(float): The current parameter value.
				eigenvalue (complex): The eigenvalue corresponding to the specified eigenindex.

        Raises:
				RuntimeError: If the eigenindex is greater than or equal to neigen.
				RuntimeError: If the initial solution is already unstable.
        """
       
        
        
        max_ds_func=max_ds
        if isinstance(parameter, str):
            parameter = self.get_global_parameter(parameter)
        if do_solve:
            self.solve(spatial_adapt=spatial_adapt)
        else:
            if not self.is_initialised():
                self.initialise()
        if eigenindex>=neigen:
            raise RuntimeError("eigenindex must be less than neigen")
        # Get the initial eigenvalues                    
        if azimuthal_m is None or azimuthal_m==0:
            evals0, _ = self.solve_eigenproblem(neigen, shift=shift)
        else:
            evals0, _ = self.solve_axial_symmetry_breaking_eigenproblem(neigen, azimuthal_m, shift=shift)
        self.invalidate_cached_mesh_data()
        param0 = parameter.value
        sign0 = evals0[eigenindex].real
        if evals0[eigenindex].real > epsilon:
            raise RuntimeError("Starting already with an unstable solution")
        elif evals0[eigenindex].real >= -epsilon:
            yield param0, evals0[eigenindex]
            return
        if stay_stable_file is not None:
            self.save_state(stay_stable_file,relative_to_output=True)
        ds = initstep
        firstSignChange = False
        if reset_arclength:
            self.reset_arc_length_parameters()
        while True:
            ds0 = ds
            if do_solve:
                if callable(max_ds_func):
                    max_ds=max_ds_func(parameter.value)
                    max_ds=abs(max_ds)
                    print("MAX DS SET TO",max_ds)
                ds = self.arclength_continuation(parameter, ds,max_ds=max_ds)
                self.invalidate_cached_mesh_data()
            else:
                parameter.value=parameter.value+ds
                if max_ds is not None:
                    if callable(max_ds_func):
                        max_ds=max_ds_func(parameter.value)
                        max_ds=abs(max_ds)
                        print("MAX DS SET TO",max_ds)
                    ds=min(abs(1.5*ds),max_ds)*(1 if ds>0 else -1)
            if reset_arclength:
                self.reset_arc_length_parameters()
            if before_eigensolving is not None:
                before_eigensolving(param0)
            if azimuthal_m is None:
                evals1, _ = self.solve_eigenproblem(neigen, shift=shift)
            else:
                evals1,_=self.solve_axial_symmetry_breaking_eigenproblem(neigen, azimuthal_m, shift=shift)
            self.invalidate_cached_mesh_data()
            param1 = parameter.value
            if abs(evals1[eigenindex].real) < epsilon:
                yield param1, evals1[eigenindex]
                return
            sign = evals1[eigenindex].real
            if sign * sign0 < 0:
                if (stay_stable_file is not None) and evals1[eigenindex].real > epsilon:
                    self.load_state(stay_stable_file, relative_to_output=True)
                    self.invalidate_cached_mesh_data()
                    self.reset_arc_length_parameters()
                    # find the intersection with zero by linear approximation
                    # eigenval=(evals1[0].real-evals0[0].real)/(param1-param0)*(p-param0)+evals0[0].real
                    ds=-evals0[eigenindex].real*(param1-param0)/(evals1[eigenindex].real-evals0[eigenindex].real)
                    continue

                firstSignChange = True
                dsmagn = max(abs(ds), abs(ds0))
                ds = -0.5 * dsmagn * (-1 if ds < 0 else 1)
            else:
                if firstSignChange:
                    dsmagn = max(abs(ds), abs(ds0))
                    ds = dsmagn * (-1 if ds < 0 else 1)
                    ds = ds0 - 0.5 * ds
            yield param1, evals1[eigenindex]
            if (stay_stable_file is not None) and evals1[eigenindex].real<epsilon:
                self.save_state(stay_stable_file, relative_to_output=True)
            sign0 = sign
            evals0=evals1
            param0=param1

    def set_max_refinement_level(self,level:int):
        if level<0:
            raise RuntimeError("Must be >=0")
        
        def set_level_for_mesh(mesh:AnySpatialMesh,level):            
            assert isinstance(mesh,MeshFromTemplate2d)            
            mesh._templatemesh.get_template()._max_refinement_level=level            
            maxref=0
            for e in mesh.elements():
                maxref=max(maxref,e.refinement_level())
            res=maxref-mesh.max_refinement_level               
            mesh.max_refinement_level=level
            return res
        must_unref=0
        for _n,m in self._meshdict.items():
            if not isinstance(m,ODEStorageMesh):
                must_unref=max(must_unref, set_level_for_mesh(m,level))
        self.max_refinement_level=level
        if must_unref>0:
            with self.custom_adapt():
                for i in range(must_unref):
                    self.adapt()


    def perturb_dofs(self,dofpert:NPFloatArray):
        """
        Perturbs all degrees of freedom by a given perturbation array (must have the length of :py:meth:`ndof`)

        Args:
            dofpert: Perturbation array to be added to the degrees of freedom (nondimensional)
        """
        dofs,_=self.get_current_dofs()
        self.invalidate_cached_mesh_data()
        self.invalidate_eigendata()
        self.set_current_dofs(numpy.array(dofs)+dofpert) #type:ignore

    def deactivate_bifurcation_tracking(self):
        
        """
        Deactivate bifurcation tracking. Afterwards, the problem can be solved as usual.
        """
        
        last_tracking=self.get_bifurcation_tracking_mode()
        self._start_bifurcation_tracking("","",False,[],[],0.0,{})
        self._bifurcation_tracking_parameter_name=None        
        if last_tracking=="azimuthal":
            self.actions_before_stationary_solve()
            self.reapply_boundary_conditions()
            self._last_bc_setting="normal"
            self._azimuthal_mode_param_m.value=0

    # Assuming that Re(lambda)=0 is also stable, which is not exactly true
    def is_stable_solution(self)->bool:
        """
        Shortcut to check whether we have a stable solution. This is only possible after calling solve_eigenproblem(...).
        """
        if len(self._last_eigenvalues)==0:
            raise RuntimeError("Can only find out whether a solution is stable after calling solve_eigenproblem(...)")
        if self.get_bifurcation_tracking_mode()!="":
            raise RuntimeError("Cannot find out whether a solution is stable when bifurcation tracking is active")
        return numpy.real(self._last_eigenvalues[0])<=0 #type:ignore

    def guess_nearest_bifurcation_type(self,eigenvector:int=0)->Literal["hopf","fold","pitchfork","azimuthal"]:
        """
        Guesses the nearest bifurcation type based on the last computed eigenvalues. This is only possible after calling solve_eigenproblem(...).
        It cannot guess e.g. pitchfork or transcritical bifurcations, only "hopf" or "fold" - or "azimuthal" if the last eigenvalues correspond to azimuthal modes m!=0.
        Returns:
            str: Guessed bifurcation type
        """
        if len(self._last_eigenvalues)==0:
            raise RuntimeError("Can only guess the closest bifurcation type after calling solve_eigenproblem(...)")
        if self.get_bifurcation_tracking_mode()!="":
            raise RuntimeError("Cannot guess the closest bifurcation type when bifurcation tracking is active")
        if self._last_eigenvalues_m is None or len(self._last_eigenvalues_m)==0 or self._last_eigenvalues_m[eigenvector]==0:
            if abs(numpy.imag(self._last_eigenvalues[eigenvector]))<1e-7:
                return "fold"
            else:
                return "hopf"
        else:
            return "azimuthal"


    def activate_bifurcation_tracking(self,parameter:Union[str,_pyoomph.GiNaC_GlobalParam],bifurcation_type:Optional[Literal["hopf","fold","pitchfork","azimuthal"]]=None,blocksolve:bool=False,eigenvector:Optional[Union[NPFloatArray,NPComplexArray,int]]=None,omega:Optional[float]=None,azimuthal_mode:Optional[int]=None):
        """
        Activates bifurcation tracking for the specified parameter and bifurcation type. Subsequent calls of solve(...) and arclength_continuation(...) will then track the bifurcation.

        Args:
            parameter (Union[str, _pyoomph.GiNaC_GlobalParam]): The parameter to change in order to find the bifurcation.
            bifurcation_type (Optional[Literal["hopf", "fold", "pitchfork", "azimuthal"]]): The type of bifurcation to track. Defaults to None, i.e. auto-detect.
            blocksolve (bool): Flag indicating whether to use block solve. Defaults to False. Should be kept False.
            eigenvector (Optional[Union[NPFloatArray, NPComplexArray, int]]): The eigenvector to use for tracking. Defaults to None, which means the eigenvector corresponding to the eigenvalue with largest real part. Can be either an index or a custom vector.
            omega (Optional[float]): The omega value for Hopf bifurcation tracking. Defaults to None, then it will be Im(lambda).
            azimuthal_mode (Optional[int]): The azimuthal mode for azimuthal bifurcation tracking. Defaults to None.
        """        
        
        

        #def prerotate_eigenvector(ev):
        #    Gr = numpy.real(ev)
        #    Gi = numpy.imag(ev)
        #    GrGr = numpy.dot(Gr, Gr)
        #    GiGi = numpy.dot(Gi, Gi)
        #    GrGi = numpy.dot(Gr, Gi)
        #    print("DOTS ARE",GrGr,GiGi,GrGi)
        #    # Phase to rotate it that gr*gi=0
        #    phi = numpy.arctan2(( GrGr-GiGi  + numpy.sqrt((GrGr - GiGi) ** 2 + 4 * GrGi ** 2)), (2 * GrGi))
        #    print("phi is ",phi)
        #    # Apply rotation
        #    gr = Gr * numpy.cos(phi) - Gi * numpy.sin(phi)
        #    gi = Gr * numpy.sin(phi) + Gi * numpy.cos(phi)
        #    # vector normalized to fulfill gr*gr=1 back to guess
        #    return  (gr + (0 + 1j) * gi) / numpy.sqrt(numpy.dot(gr, gr))

        if isinstance(eigenvector,int):
            if eigenvector>=len(self.get_last_eigenvectors()):
                raise RuntimeError("Eigenvector "+str(eigenvector)+" not calculated")
            if bifurcation_type is None:
                bifurcation_type=self.guess_nearest_bifurcation_type(eigenvector)
                print("Assuming nearest bifurcation is of type: "+bifurcation_type)
            if omega is None and bifurcation_type in {"hopf","azimuthal"}:
                omega=numpy.imag(self.get_last_eigenvalues()[eigenvector])
            if bifurcation_type=="azimuthal" and azimuthal_mode is None:
                azimuthal_mode=self.get_last_eigenmodes_m()[eigenvector]
            eigenvector=self.get_last_eigenvectors()[eigenvector]
            
        if bifurcation_type is None:
            bifurcation_type=self.guess_nearest_bifurcation_type()
            print("Assuming nearest bifurcation is of type: "+bifurcation_type)

        if self._dof_selector_used is not self._dof_selector:
            self.reapply_boundary_conditions()
        if isinstance(parameter,_pyoomph.GiNaC_GlobalParam):
            parameter=parameter.get_name()
        if not self.is_quiet():
            print("Bifurcation tracking activated for "+parameter)
        self._bifurcation_tracking_parameter_name=parameter
        if bifurcation_type=="fold":
#            must_reapply_bcs=self._equation_system._before_eigen_solve(self.get_eigen_solver(), 0)
#            if must_reapply_bcs:
#                self.reapply_boundary_conditions() # Equation numbering might have been changed. Update it here!
#                self._last_bc_setting="eigen"
            if azimuthal_mode is not None:
                raise RuntimeError("Cannot use azimuthal_mode for fold solving")
            if eigenvector is None:
                eigenvector = next(iter(self.get_last_eigenvectors()), None)
            if eigenvector is None or len(eigenvector)==0:
                self._start_bifurcation_tracking(parameter,bifurcation_type,blocksolve,[],[],0.0,{})
            else:
                self._start_bifurcation_tracking(parameter,bifurcation_type,blocksolve,numpy.real(eigenvector),[],0.0,{}) #type:ignore
        elif bifurcation_type=="hopf":
            if azimuthal_mode is not None:
                raise RuntimeError("Cannot use azimuthal_mode for fold solving")
            if eigenvector is None:
                eigenvector=next(iter(self.get_last_eigenvectors()),None)
            if omega is None:
                omega=next(iter(self.get_last_eigenvalues()),None)
                if omega is not None:
                    omega=numpy.imag(omega) #type:ignore
            if eigenvector is None:
                raise RuntimeError("Please pass the kwarg eigenvector to the bifurcation tracking for Hopf bifurcations")
            elif omega is None:
                raise RuntimeError("Please pass a guess to omega for a Hopf bifurcation")
            elif float(omega)==0.0:
                raise RuntimeError("Hopf bifurcation cannot have zero complex part of the eigenvalue")
            else:
                #if not self.is_quiet():
                    #print("OMEGA",omega,numpy.real(eigenvector),numpy.imag(eigenvector))
                    #print("PARAMDERIV",self.get_parameter_derivative(parameter))
                #print("STARTING WITH OMEGA=",omega)
                #eigenvector=prerotate_eigenvector(eigenvector)
                #eigenvector = prerotate_eigenvector(eigenvector)
                #print(eigenvector)

                # NOTE THAT WE NEGATE OMEGA HERE!
                # In fact, pyoomph is solving the eigenproblem -lambda*M*v=J*v, which leads to this inversion
                # Opposed to oomph-lib, pyoomph get's the mass matrix by deriving J with respect to occurences of first order time derivatives.
                # Since both comes from the same residual, it can only be consistent if either M or J is negated
                # In the eigensolver, we negate J (since eigensolvers may demand M to be positive (semi-)definite.
                # In the bifurcation tracking, we just negate omega, for the very same result
                self._start_bifurcation_tracking(parameter,bifurcation_type,blocksolve,numpy.real(eigenvector),numpy.imag(eigenvector),-omega,{}) #type:ignore
        elif bifurcation_type=="pitchfork":
            if azimuthal_mode is not None:
                raise RuntimeError("Cannot use azimuthal_mode for fold solving")
            if eigenvector is None:
                eigenvector=next(iter(self.get_last_eigenvectors()),None)
            if eigenvector is None:
                raise RuntimeError("Pitchfork tracking requires at least a symmetry vector passed via the eigenvector kwarg")
            self._start_bifurcation_tracking(parameter,bifurcation_type,blocksolve,numpy.real(eigenvector),[],0.0,{}) #type:ignore
        elif bifurcation_type=="azimuthal":
            if self._azimuthal_mode_param_m is None:
                raise RuntimeError("Cannot use azimuthal bifurcation tracking if not called define_problem_for_axial_symmetry_breaking_investigation() before")
            if azimuthal_mode is None:
                # Try to get the most unstable mode
                if self._last_eigenvalues_m is None or len(self._last_eigenvalues_m)==0:
                    raise RuntimeError("Must specify azimuthal_mode or solve an azimuthal eigenproblem before")
                azimuthal_mode=self._last_eigenvalues_m[0]
                assert azimuthal_mode is not None
            self._azimuthal_mode_param_m.value=azimuthal_mode
            if eigenvector is None:
                if self._last_eigenvalues_m is None or len(self._last_eigenvalues_m) == 0:
                    raise RuntimeError("Cannot find a good eigenvector guess since you have not calculated any one for mode "+str(azimuthal_mode))
                # Try to find an eigenvector corresponding to this mode
                eigenindices = numpy.where(numpy.array(self._last_eigenvalues_m)==azimuthal_mode)[0] #type:ignore
                if len(eigenindices)==0:
                    raise RuntimeError("Cannot find a good eigenvector guess since you have not calculated any one for mode " + str(azimuthal_mode))
                eigenvector = self.get_last_eigenvectors()[eigenindices[0]]
                if omega is None:
                    omega=numpy.imag(self.get_last_eigenvalues()[eigenindices[0]]) #type:ignore
            if omega is None:
                omega = next(iter(self.get_last_eigenvalues()), None)
            if omega is not None:
                omega = numpy.imag(omega) #type:ignore
            else:
                omega = 0

            # First, we get all equations which must be zero for the base state and on the eigenvector
            must_reapply_bcs=self._equation_system._before_eigen_solve(self.get_eigen_solver(), azimuthal_mode)
            if must_reapply_bcs:
                self.reapply_boundary_conditions() # Equation numbering might have been changed. Update it here!
                self._last_bc_setting="eigen"
            base_zero_dofs=self._equation_system._get_forced_zero_dofs_for_eigenproblem(self.get_eigen_solver(),0) 
            eigen_zero_dofs=self._equation_system._get_forced_zero_dofs_for_eigenproblem(self.get_eigen_solver(),azimuthal_mode) 

            # These are sets of strings, we must convert them into lists of equations. We reuse the same class as for the eigenproblem
            def dof_strings_to_global_equations(string_dof_set:Set[str]):
                from ..solvers.generic import EigenMatrixSetDofsToZero
                resolver=EigenMatrixSetDofsToZero(self,*string_dof_set)
                zeromap:Set[int]=set()
                for d in resolver.doflist:
                    eqs=resolver.resolve_equations_by_name(d)
                    zeromap=zeromap.union(eqs)
                return zeromap

            base_zero_dofs=dof_strings_to_global_equations(base_zero_dofs)
            eigen_zero_dofs=dof_strings_to_global_equations(eigen_zero_dofs)


            contribs={"azimuthal_real_eigen":self._azimuthal_stability.real_contribution_name,"azimuthal_imag_eigen":self._azimuthal_stability.imag_contribution_name}

            # NOTE THAT WE NEGATE OMEGA HERE!
            # In fact, pyoomph is solving the eigenproblem -lambda*M*v=J*v, which leads to this inversion
            # Opposed to oomph-lib, pyoomph get's the mass matrix by deriving J with respect to occurences of first order time derivatives.
            # Since both comes from the same residual, it can only be consistent if either M or J is negated
            # In the eigensolver, we negate J (since eigensolvers may demand M to be positive (semi-)definite.
            # In the bifurcation tracking, we just negate omega, for the very same result
            self._start_bifurcation_tracking(parameter, bifurcation_type, blocksolve, numpy.real(eigenvector),numpy.imag(eigenvector), -omega,contribs) #type:ignore
            self.assembly_handler_pt().set_global_equations_forced_zero(base_zero_dofs,eigen_zero_dofs) #type:ignore
        else:
            raise ValueError("Unknown bifurcation type:"+str(bifurcation_type))

    def get_last_eigenvalues(self)->NPComplexArray:
        """Returns the last computed eigenvalues.

        Returns:
            NPComplexArray: Eigenvalues as array.
        """                
        return self._last_eigenvalues

    def get_last_eigenvectors(self)->NPComplexArray:
        """Return the last computed eigenvector.

        Returns:
            NPComplexArray: Eigenvectors as 2d array.
        """
        return self._last_eigenvectors

    def get_last_eigenmodes_m(self) -> Optional[NPIntArray]:
        """Get the azimuthal mode numbers for the last computed eigenvalues.

        Returns:
            Optional[NPIntArray]: Array containing the azimuthal mode numbers corresponding to the eigenvalues.
        """
        return self._last_eigenvalues_m

    # MUST BE CALLED FROM define_problem(), at best towards the end
    def define_problem_for_axial_symmetry_breaking_investigation(self):
        from ..expressions.coordsys import AxisymmetryBreakingCoordinateSystem
        self._azimuthal_mode_param_m = self.get_global_parameter(self._azimuthal_stability.azimuthal_param_m_name)
        coordsys = AxisymmetryBreakingCoordinateSystem(self._azimuthal_mode_param_m.get_symbol())
        self.set_coordinate_system(coordsys)

        if len(self._residual_mapping_functions) != 0:
            raise RuntimeError("TODO: combine it with more residual mapping functions")
        self._residual_mapping_functions = [
            lambda dest, expr: {dest: coordsys.map_residual_on_base_mode(expr),
                                self._azimuthal_stability.real_contribution_name+dest: coordsys.map_residual_on_angular_eigenproblem_real(expr),
                                self._azimuthal_stability.imag_contribution_name+dest: coordsys.map_residual_on_angular_eigenproblem_imag(expr)}]




    def setup_forced_zero_dof_list_for_eigenproblems(self):
        if self._azimuthal_mode_param_m is not None:
            mv=self._azimuthal_mode_param_m.value
            m=round(mv)
            if abs(m-mv)>1e-6:
                raise RuntimeError("Angular mode m is not an integer! "+str(mv))
        else:
            m=None
        to_zero_dofs=self._equation_system._get_forced_zero_dofs_for_eigenproblem(self.get_eigen_solver(),m) 
        if len(to_zero_dofs) and _pyoomph.get_verbosity_flag()!=0:
            print("For the eigenvalues "+("" if m is None else "[azimuthal_m="+str(int(m))+"]")+" we set following fields to zero: "+str(to_zero_dofs))        
        from ..solvers.generic import EigenMatrixSetDofsToZero
        esolve = self.get_eigen_solver()
        esolve.clear_matrix_manipulators()  # Flush the matrix manipulators
        if len(to_zero_dofs)>0:
            # And add a Matrix manipulator that sets the constrained degrees of freedom to zero
            esolve.add_matrix_manipulator(EigenMatrixSetDofsToZero(self, *to_zero_dofs))

    def solve_axial_symmetry_breaking_eigenproblem(self, n:int, m:Union[List[int],Tuple[int],int], shift:Optional[Union[float,complex]]=0,quiet:bool=False,filter:Optional[Callable[[complex],bool]]=None,report_accuracy:bool=False)->Tuple[NPComplexArray,NPComplexArray]:
        if self._azimuthal_mode_param_m is None:
            raise RuntimeError(
                "Must call define_problem_for_axial_symmetry_breaking_investigation towards the end of define_problem before using this")
        if isinstance(m,(list,tuple)):
            if report_accuracy:
                raise RuntimeError("report_accuracy=True for azimuthal symmetry breaking only works if you select a single azimuthal mode, not a list like "+str(m))
            alleigenvals:NPComplexArray=numpy.array([],dtype=numpy.complex128) #type:ignore
            alleigenvects:NPComplexArray=numpy.array([],dtype=numpy.complex128) #type:ignore
            minfoL:List[int]=[]
            for ms in m:
                self._azimuthal_mode_param_m.value = ms
                self.actions_before_eigen_solve()
                self.solve_eigenproblem(n, shift,quiet=True,filter=filter,report_accuracy=report_accuracy)
                if len(alleigenvals)==0:
                    alleigenvals=self.get_last_eigenvalues().copy()
                else:
                    alleigenvals:NPComplexArray=numpy.hstack([alleigenvals,self.get_last_eigenvalues().copy()]) #type:ignore
                minfoL+=[ms]*len(self.get_last_eigenvalues())
                if len(alleigenvects)==0:
                    alleigenvects:NPComplexArray= numpy.array(self.get_last_eigenvectors()).copy() #type:ignore
                else:
                    #print(alleigenvects)
                    #print(self.get_last_eigenvectors())
                    #print(alleigenvects.shape,self.get_last_eigenvectors().shape)
                    alleigenvects:NPComplexArray=numpy.vstack([alleigenvects,numpy.array(self.get_last_eigenvectors()).copy()]) #type:ignore

            srt = numpy.argsort(-alleigenvals) #type:ignore
            alleigenvals:NPComplexArray=alleigenvals[srt] #type:ignore

            alleigenvects:NPComplexArray = alleigenvects[srt,:] #type:ignore
            minfo:NPIntArray=numpy.array(minfoL)[srt] #type:ignore

            self._last_eigenvalues, self._last_eigenvectors,self._last_eigenvalues_m = alleigenvals,alleigenvects,minfo
            if (not self.is_quiet()) and (not quiet):
                for i, l in enumerate(self._last_eigenvalues):
                    m=minfo[i]
                    print("Eigenvalue [m="+str(m)+"]", i, ":", l)
            self._azimuthal_mode_param_m.value = 0
        else:
            self._azimuthal_mode_param_m.value = m
            self.actions_before_eigen_solve()
            self.solve_eigenproblem(n, shift,filter=filter,report_accuracy=report_accuracy)
            self._azimuthal_mode_param_m.value = 0
            self._last_eigenvalues_m=numpy.array([m]*len(self.get_last_eigenvalues()),dtype=numpy.int32) #type:ignore

        return self._last_eigenvalues, self._last_eigenvectors

    # will be called when a stationary solve is tried after a transient solve or when solving for the first time
    def actions_before_stationary_solve(self,force_reassign_eqs:bool=False):
        must_reassign_eqs=self._equation_system._before_stationary_or_transient_solve(stationary=True) 
        if must_reassign_eqs or force_reassign_eqs:
            self.reapply_boundary_conditions()
            self.relink_external_data()
            self.reapply_boundary_conditions()
            self._last_bc_setting="stationary"


    # will be called when a transient solve is tried after a stationary solve or when solving for the first time
    def actions_before_transient_solve(self,force_reassign_eqs:bool=False):
        must_reassign_eqs = self._equation_system._before_stationary_or_transient_solve(stationary=False) 
        if must_reassign_eqs or force_reassign_eqs:
            self.reapply_boundary_conditions()
            self.relink_external_data()
            self.reapply_boundary_conditions()
            self._last_bc_setting="transient"

    # will be called when an eigenproblem is about to be solved
    def actions_before_eigen_solve(self,force_reassign_eqs:bool=False): 
        eigen_m=None
        if self._azimuthal_mode_param_m is not None:
            mv=self._azimuthal_mode_param_m.value
            eigen_m=round(mv)
            if abs(eigen_m-mv)>1e-6:
                raise RuntimeError("Angular mode m is not an integer! "+str(mv))
        must_reassign_eqs = self._equation_system._before_eigen_solve(self.get_eigen_solver(),eigen_m) 
        if must_reassign_eqs or force_reassign_eqs:
            self.reapply_boundary_conditions()
            self.relink_external_data()
            self.reapply_boundary_conditions()
            self._last_bc_setting="eigen"

        if eigen_m is not None and int(eigen_m)!=0:
            self.get_eigen_solver().setup_matrix_contributions(self._azimuthal_stability.real_contribution_name,self._azimuthal_stability.imag_contribution_name)
        else:
            self.get_eigen_solver().setup_matrix_contributions("",None)

    def solve(self,*,spatial_adapt:int=0,timestep:Union[ExpressionNumOrNone,List[ExpressionNumOrNone]]=None,shift_values:bool=True,temporal_error:Optional[float]=None,max_newton_iterations:Optional[int]=None,newton_relaxation_factor:Optional[float]=None,suppress_resolve_after_adapt:bool=False,newton_solver_tolerance:Optional[float]=None,do_not_set_IC:bool=False,globally_convergent_newton:bool=False)->ExpressionOrNum: #,continuation=None)
        """
        Solves the problem stationary, unless a timestep is given. In that case, the time step is taken.

        Parameters:
        - spatial_adapt (int): The level of spatial adaptation. Default is 0.
        - timestep (Union[ExpressionNumOrNone, List[ExpressionNumOrNone]]): The time step(s) for the transient solve. Can be a single value or a list of values. Default is None, meaning stationary solve without advancing in time.
        - shift_values (bool): Whether to shift the values during the solve, i.e. shifting the history value buffer. Default is True.
        - temporal_error (Optional[float]): The temporal error for adaptive time stepping. Default is None.
        - max_newton_iterations (Optional[int]): Override the maximum number of Newton iterations. Default is None.
        - newton_relaxation_factor (Optional[float]): Override the relaxation factor for the Newton solver. Default is None.
        - suppress_resolve_after_adapt (bool): Whether to suppress resolving after adaptation. Default is False.
        - newton_solver_tolerance (Optional[float]): Override the tolerance for the Newton solver. Default is None.
        - do_not_set_IC (bool): Whether to not set the initial condition in the first call. Default is False.
        - globally_convergent_newton (bool): Whether to use globally convergent Newton solver. Default is False.

        Returns:
        - ExpressionOrNum: The current time after solving.
        """  
                

        if isinstance(timestep,(list,tuple)):
            lastres=0
            for t in timestep: #type:ignore
                assert isinstance(t,(float,int,Expression)) or t is None
                lastres=self.solve(timestep=t,spatial_adapt=spatial_adapt,shift_values=shift_values,temporal_error=temporal_error,max_newton_iterations=max_newton_iterations,newton_relaxation_factor=newton_relaxation_factor,suppress_resolve_after_adapt=suppress_resolve_after_adapt,newton_solver_tolerance=newton_solver_tolerance,globally_convergent_newton=globally_convergent_newton)
            return lastres

        timestep_normalized=False
        self._activate_solver_callback()
        self.invalidate_cached_mesh_data()
        if isinstance(spatial_adapt,bool) and spatial_adapt==True:
            spatial_adapt=self.max_refinement_level

        TSCALE=self.scaling.get("temporal",1)
        assert not isinstance(TSCALE,str)

        if not self.is_initialised():
            self.initialise()
            self._activate_solver_callback()
            if (timestep is not None):
                timestep=timestep/TSCALE
                try:
                    timestep=float(timestep)
                except RuntimeError as _:
                    raise RuntimeError("Time step needs to match the dimension of the temporal scale "+str(self.scaling.get("temporal",1)))
                timestep_normalized=True
                if self._runmode!="continue":
                    self.initialise_dt(timestep)
                    if not do_not_set_IC:
                        self.set_initial_condition()
                    self.timestepper.set_num_unsteady_steps_done(0)
                    self._taken_already_an_unsteady_step=True
        elif self._taken_already_an_unsteady_step==False and (timestep is not None):
            timestep = timestep / TSCALE
            try:
                timestep = float(timestep)
            except RuntimeError as _:
                raise RuntimeError("Time step needs to match the dimension of the temporal scale " + str(self.scaling.get("temporal", 1)))
            timestep_normalized = True
            self.initialise_dt(timestep)
            if not do_not_set_IC:
                self.set_initial_condition() #This will calc the weights etc and history values correctly
            self.timestepper.set_num_unsteady_steps_done(0)
            self._taken_already_an_unsteady_step = True

        oldsettings=self._override_for_this_solve(max_newton_iterations=max_newton_iterations,newton_relaxation_factor=newton_relaxation_factor,newton_solver_tolerance=newton_solver_tolerance,globally_convergent_newton=globally_convergent_newton)
#		if continuation:
#			if (not isinstance(continuation,list)) or len(continuation)!=2:
#				raise ValueError("kwarg continuation needs to be a list [global parameter, step]")
#			res=self.arclength_continuation(continuation[0],continuation[1],spatial_adapt=spatial_adapt)
#			self._override_for_this_solve(**oldsettings)
#			return res

        paramstr = ""
        paramnames=[pn for pn in self.get_global_parameter_names() if not pn.startswith("_")]        
        if len(paramnames) > 0:
            paramstr = ". Parameters: " + ", ".join(
                [n + "=" + str(self.get_global_parameter(n).value) for n in paramnames])

        if self._dof_selector_used is not self._dof_selector:
            self.reapply_boundary_conditions()

        #Get rid of the eigen info... It will change!
        self.invalidate_eigendata()
        
        if timestep is None:
            self.actions_before_stationary_solve()
            if not self.is_quiet():
                print("STATIONARY SOLVE"+paramstr)
            self.steady_newton_solve(spatial_adapt)
            self._last_step_was_stationary = True
            if self.get_bifurcation_tracking_mode()!="":
                # NOTE THAT WE NEGATE OMEGA HERE!
                # In fact, pyoomph is solving the eigenproblem -lambda*M*v=J*v, which leads to this inversion
                # Opposed to oomph-lib, pyoomph get's the mass matrix by deriving J with respect to occurences of first order time derivatives.
                # Since both comes from the same residual, it can only be consistent if either M or J is negated
                # In the eigensolver, we negate J (since eigensolvers may demand M to be positive (semi-)definite.
                # In the bifurcation tracking, we just negate omega, for the very same result
                self._last_eigenvalues=numpy.array([0-self._get_bifurcation_omega()*1j],dtype=numpy.complex128) #type:ignore
                self._last_eigenvectors=numpy.array([self._get_bifurcation_eigenvector()],dtype=numpy.complex128) #type:ignore
                if self.get_bifurcation_tracking_mode()=="azimuthal":
                    self._last_eigenvalues_m=numpy.array([int(self._azimuthal_mode_param_m.value)],dtype=numpy.int32) #type:ignore
                self._last_eigenvectors=self.process_eigenvectors(self._last_eigenvectors)
            else:
                self._last_eigenvalues_m=None
            self._override_for_this_solve(**oldsettings)
            return 0
        else:
            if (timestep is not None) and (not timestep_normalized):
                timestep=timestep/TSCALE
                try:
                    timestep=float(timestep)
                except RuntimeError as _:
                    raise RuntimeError("Time step needs to match the dimension of the temporal scale "+str(self.scaling.get("temporal",1)))
                timestep_normalized=True
            if not self.is_quiet():
                print("TRANSIENT SOLVE with nondim dt",timestep,"at current time "+str(self.get_current_time(as_float=False))+paramstr)

            self.actions_before_transient_solve()
            self._last_step_was_stationary=False
            assert isinstance(timestep,(float,int))
            if spatial_adapt==0:                
                if temporal_error is None:
                    desired_dt=timestep                    
                    self.unsteady_newton_solve(timestep,shift_values)
                else:
                    desired_dt=self.adaptive_unsteady_newton_solve(timestep,temporal_error,shift_values)
                self._first_step=False
                self._override_for_this_solve(**oldsettings)
                self.timestepper.increment_num_unsteady_steps_done()
                return desired_dt*TSCALE
            else:
                if self._first_step:
                    self._resetting_first_step=True
                else:
                    self._resetting_first_step=False
                if temporal_error is None:
                    desired_dt=timestep
                    self.unsteady_newton_solve(timestep,spatial_adapt,self._first_step,shift_values)
                else:
                    desired_dt=self.doubly_adaptive_unsteady_newton_solve(timestep,temporal_error,spatial_adapt,int(suppress_resolve_after_adapt),self._first_step,shift_values)
                self._first_step=False
                self._override_for_this_solve(**oldsettings)
                self.timestepper.increment_num_unsteady_steps_done()
                return desired_dt*TSCALE


    def run(self, endtime:ExpressionOrNum, timestep:ExpressionNumOrNone=None,*, outstep:Union[ExpressionNumOrNone,bool]=None, numouts:Optional[int]=None, out_initially:Union[bool,None]=None,
            temporal_error:Union[None,float]=None, outstep_relative_to_zero:bool=True,spatial_adapt:int=0,startstep:ExpressionNumOrNone=None,maxstep:ExpressionNumOrNone=None,newton_solver_tolerance:Union[None,float]=None,do_not_set_IC:bool=False,globally_convergent_newton:bool=False,max_newton_iterations:Union[None,int]=None,starttime:ExpressionNumOrNone=None,suppress_resolve_after_adapt=False,max_newton_to_increase_time_step:Optional[int]=None)->ExpressionOrNum:
        """
        Run the problem for a specified duration, potential with output calls and temporal and/or spatial adaptivity.
        All time quantities must be given in dimensional units, e.g. ``second``, if you use e.g. :py:meth:`~Problem.set_scaling` with e.g. ``temporal=1*second`` for a dimensional problem.

        Args:
            endtime: The end time of the simulation.
            timestep: The time step size. If not specified, it will be determined automatically, e.g. by the outstep.
            outstep: The time interval between outputs. If set to True, outputs will be generated at each time step. If set to False, no outputs will be generated. If not specified, it will be set to the value of `timestep`.
            numouts: The number of outputs to generate. If specified, it will override the value of `outstep`.
            out_initially: Whether to generate an output at the initial time. If not specified, it will be set to `True` if `outstep` is not `False`, otherwise it will be set to `False`.
            temporal_error: The temporal error tolerance. If specified, it will be used to control the time step size.
            outstep_relative_to_zero: Whether the `outstep` is relative to the initial time or the current time. If set to `True`, the `outstep` will be relative to the initial time. If set to `False`, the `outstep` will be relative to the current time.
            spatial_adapt: The level of spatial adaptation. If specified, it will be used to control the spatial refinement level.
            startstep: The time step size at the start of the simulation (for temporal adaptivity). If specified, it will override the value of `timestep`.
            maxstep: The maximum time step size. If specified, it will be used to limit the time step size during temporal adaptivity.
            newton_solver_tolerance: The tolerance for the Newton solver. If specified, it will be used to control the convergence of the solver during this run call.
            do_not_set_IC: Whether to set the initial condition. If set to `True`, the initial condition will not be set.
            globally_convergent_newton: Whether to use a globally convergent Newton solver. If set to `True`, a globally convergent Newton solver will be used.
            max_newton_iterations: The maximum number of iterations for the Newton solver. If specified, it will override to limit the number of iterations for this run call.
            starttime: The start time of the simulation. If specified, it will override the current time.
            suppress_resolve_after_adapt: Whether to suppress the resolve after adaptation. If set to `True`, the resolve after adaptation will be suppressed.
            max_newton_to_increase_time_step: The maximum number of Newton iterations to increase the time step size. If specified, the adaptive time step will only be increased if the number of Newton iterations is less than this value.

        Returns:
            The final time of the simulation after the run call.

        Raises:
            ValueError: If `endtime` is not specified.
            ValueError: If `outstep` and `numouts` are specified simultaneously.
            RuntimeError: If a suitable time step cannot be determined.

        """
        if endtime is None:
            raise ValueError("Must specify an endtime")

        if spatial_adapt>self.max_refinement_level:
            spatial_adapt=self.max_refinement_level
        elif isinstance(spatial_adapt,bool) and spatial_adapt==True:
            spatial_adapt=self.max_refinement_level

        if temporal_error is not None and temporal_error <= 0:
            temporal_error = None

        if numouts is not None and numouts <= 0:
            numouts = None
            outstep = False

        if (outstep is not None):
            if numouts is not None:
                raise ValueError("Cannot use outstep and numouts simultaneously")

        if isinstance(numouts,bool) and numouts == True:
            outstep=True
            numouts=None

        if starttime is not None:
            self.set_current_time(starttime)
        if (not self.is_initialised()) or self._taken_already_an_unsteady_step==False:
            #We need to calculate the initial time step already now to initialize appropriately!
            _tstart=self.get_current_time() #This might call initialise!
            if self._runmode!="continue":
                if numouts is not None:
                    if isinstance(numouts,bool) and numouts==True:
                        raise RuntimeError("TODO: Init with a suitable time step")
                    else:
                        _ts=float((endtime-_tstart)/(numouts*self.get_scaling("temporal")))
                        self.initialise_dt(_ts)
                        if not do_not_set_IC:
                            self.set_initial_condition()
                elif startstep is not None:
                    _ts=float(startstep/self.get_scaling("temporal"))
                    self.initialise_dt(_ts)
                    if not do_not_set_IC:
                        self.set_initial_condition()
                elif timestep is not None:
                    _ts = float(timestep / self.get_scaling("temporal"))
                    self.initialise_dt(_ts)
                    if not do_not_set_IC:
                        self.set_initial_condition()
                elif isinstance(outstep,float) or isinstance(outstep,_pyoomph.Expression) or (isinstance(outstep,int) and not (isinstance(outstep,bool))):
                    _ts = float(outstep / self.get_scaling("temporal"))
                    self.initialise_dt(_ts)
                    if not do_not_set_IC:
                        self.set_initial_condition()
                elif maxstep is not None:
                    _ts = float(maxstep / self.get_scaling("temporal"))
                    self.initialise_dt(_ts)
                    if not do_not_set_IC:
                        self.set_initial_condition()
                else:
                    raise RuntimeError("TODO: Init with a suitable time step. Pass e.g. startstep as keyword arg")
                if out_initially is None:
                        out_initially = outstep != False
            if out_initially is None:
                if not self.is_initialised():
                    out_initially = outstep != False
                else:
                    out_initially = False
            if out_initially and self._runmode!="continue":
                self.output()

        starttime = self.get_current_time()
        _tfactor,_tunit=assert_dimensional_value(starttime-endtime)
        if _tfactor>=0.0:
            print("Skipping run call since starttime "+str(starttime)+" is larger than endtime "+str(endtime))
            self._nondim_time_after_last_run_statement=float(endtime/self.get_scaling("temporal"))
            return 0
        elif self._runmode=="continue":
            # Calculate the remaining numouts
            if numouts is not None:
                ct=float(self.get_current_time()/self.get_scaling("temporal"))
                et=float(endtime/self.get_scaling("temporal"))
                progress=(ct-self._nondim_time_after_last_run_statement)/(et-self._nondim_time_after_last_run_statement)
                numouts=int(numouts*(1-progress))
            timestep = self.timestepper.time_pt().dt(0) * self.get_scaling("temporal")

        #TODO Further checking for the end time

        if timestep is None:
            if not self.is_initialised():
                self.initialise()
                timestep = self.get_scaling("temporal")
            else:
                timestep = self.timestepper.time_pt().dt(0) * self.get_scaling("temporal")
            _tdiff,_tunit=assert_dimensional_value(starttime+timestep-endtime)
            if _tdiff>0:
                timestep=endtime-starttime
        if startstep is not None:
            timestep=startstep


        if outstep is None:
            outstep = timestep
        TS = self.get_scaling("temporal")
        ndouttimes:Optional[NPFloatArray] = None 
        if not isinstance(outstep, bool):
            currentdt = min(float(timestep / TS), float(outstep / TS)) * TS
            if maxstep is not None:
                currentdt=min(float(currentdt/TS),float(maxstep/TS))*TS
            if outstep_relative_to_zero:
                if numouts:
                    dtout = (endtime - starttime) / numouts
                    soffs = math.ceil(float(starttime / dtout)) * dtout
                    endout = soffs + numouts * dtout
                    ndouttimes = numpy.linspace(float(soffs / TS), float(endout / TS), num=numouts + 1) #type:ignore
                else:
                    dtout=outstep
                    numouts=int(float((endtime - starttime)/dtout))
                    soffs = math.ceil(float(starttime / dtout)) * dtout
                    endout = soffs + numouts * dtout
                    ndouttimes = numpy.linspace(float(soffs / TS), float(endout / TS), num=numouts + 1) #type:ignore

            else:
                if numouts:
                    ndouttimes = numpy.linspace(float((starttime) / TS), float(endtime / TS), num=numouts + 1,endpoint=True) #type:ignore
                else:
                    raise RuntimeError("TODO")
            outcntvalue=float((ndouttimes[-1]-starttime/ TS) )/(numouts)+ ndouttimes[-1]
            ndouttimes=numpy.hstack([ndouttimes,[outcntvalue]]) #type:ignore
        else:
            currentdt = timestep

        nextdt_was_clamped_for_output:ExpressionNumOrNone=None # When clamping a time step to hit the next output dt, enlarge it afterwards
        while self.get_current_time(as_float=True, dimensional=False) < float(endtime / TS):
            if self._abort_current_run:
                self._abort_current_run=False
                return currentdt
            tnd = self.get_current_time(as_float=True, dimensional=False)
            possibly_larger_dt:ExpressionNumOrNone=None
            if ndouttimes is not None:
                # Check if the current timestep would exceed the next output
                currind:int = numpy.nonzero(ndouttimes <= tnd)[0] #type:ignore
                currind = -1 if len(currind) == 0 else currind[-1] #type:ignore
                nextndout = ndouttimes[currind + 1] #type:ignore
                if tnd + float(currentdt / TS) * 1.01 > nextndout:
                    possibly_larger_dt=currentdt
                    currentdt = (nextndout - tnd) * TS

            nextdt = self.solve(timestep=currentdt, temporal_error=temporal_error,spatial_adapt=spatial_adapt,newton_solver_tolerance=newton_solver_tolerance,do_not_set_IC=do_not_set_IC,globally_convergent_newton=globally_convergent_newton,max_newton_iterations=max_newton_iterations,suppress_resolve_after_adapt=suppress_resolve_after_adapt)
            if max_newton_to_increase_time_step is not None and float(nextdt/TS)>float(currentdt/TS*1.00001):
                last_res=self.get_last_residual_convergence()
                if len(last_res)>max_newton_to_increase_time_step:
                    print("Do not increase time step, since we used too many iterations")
                    nextdt=currentdt
            
        
            if possibly_larger_dt is not None:
                if float(possibly_larger_dt/nextdt)>1.0:
                    pass
                    #print("Taking larger dt",nextdt,possibly_larger_dt)
                    #nextdt=possibly_larger_dt
            # problem._ofile.write("\t".join(map(str, [tnd, currentdt,nextdt]))+"\n")
            # problem._ofile.flush()
            if isinstance(outstep,bool) and outstep == True:
                self.output()
                if nextdt_was_clamped_for_output is not None:
                        nextdt=max(1.0,float(nextdt_was_clamped_for_output/nextdt))*nextdt 
                        nextdt_was_clamped_for_output=None
            elif outstep != False:
                tndnew = self.get_current_time(as_float=True, dimensional=False)
                nextindA = numpy.nonzero(ndouttimes <= tndnew)[0] #type:ignore
                nextind:int = -1 if len(nextindA) == 0 else nextindA[-1] #type:ignore
                if nextind > currind: #type:ignore
                    self.output()
                    if nextdt_was_clamped_for_output is not None:
                        nextdt=max(1.0,float(nextdt_was_clamped_for_output/nextdt))*nextdt 
                        nextdt_was_clamped_for_output=None
                else:
                    #  Finally check whether the next dt would be very close to the next output. If so, better do two smaller steps
                    # TODO: This needs to be checked further
                    tnext = tndnew + float(nextdt / TS) * 1.15
                    futureindA = numpy.nonzero(ndouttimes <= tnext)[0] #type:ignore
                    futureind:int = -1 if len(futureindA) == 0 else futureindA[-1] #type:ignore
                    if futureind > nextind and ndouttimes is not None:
                        #print("clamping nextdt",nextdt,(ndouttimes[futureind] - tndnew)  * TS)
                        nextdt_was_clamped_for_output=nextdt
                        nextdt = (ndouttimes[futureind] - tndnew)  * TS #type:ignore

            currentdt = nextdt
            if maxstep is not None:
                currentdt=TS*min(float(currentdt/TS),float(maxstep/TS))
            if self.get_current_time(as_float=True, dimensional=False)+float(currentdt/TS) > float(endtime / TS):
                currentdt=1.00001*float(endtime/TS-self.get_current_time(as_float=True, dimensional=False))*TS

        self._nondim_time_after_last_run_statement=float(self.get_current_time()/TS)
        return currentdt


    def force_remesh(self, only_domains:Optional[Set[MeshTemplate]]=None, num_adapt:Optional[int]=None,interpolator:Type["BaseMeshToMeshInterpolator"]=_DefaultInterpolatorClass):
        remeshers:List["RemesherBase"] = []
        if only_domains is not None:
            for t in only_domains:
                if t.remesher is not None:
                    remeshers.append(t.remesher)
        else:
            for t in self._meshtemplate_list:
                if t.remesher is not None:
                    remeshers.append(t.remesher)

        if len(remeshers)==0:
            return
        print("REMESHING")
        self.actions_before_remeshing(remeshers)
        for r in remeshers:
            r.remesh()

        

        new_meshes:Dict[str,Union[MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d]] = {}
        old_meshes:Dict[str,Union[MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d]] = {}

        # Now remove all interfaces and so on from the previous meshes
        for name, mesh in self._meshdict.items():
            if isinstance(mesh, ODEStorageMesh): continue
            for r in remeshers:
                if name in r._old_meshes.keys():                      
                    # Clean up
                    # for iname,imesh in mesh._interfacemeshes.items():
                    #    imesh.clear_before_adapt()
                    mesh = MeshFromTemplate(self, r.get_new_template(), name, r._old_meshes[name]._eqtree,previous_mesh=r._old_meshes[name]) 
                    new_meshes[name] = mesh
                    old_meshes[name] = r._old_meshes[name] 

        # Replace
        for name, newmesh in new_meshes.items():
            oldmesh = old_meshes[name]
            self._meshdict[name] = newmesh
            assert oldmesh._codegen is not None
            oldmesh._codegen._mesh = newmesh 
            assert oldmesh._codegen._code is not None            
            oldmesh._codegen._code._exchange_mesh(newmesh) 
            newmesh._construct_after_remesh() 

            for tree_depth in range(2):
                newmesh._generate_interface_elements(tree_depth)

            newmesh._tracers=oldmesh._tracers 
            for _,tracercoll in newmesh._tracers.items(): 
                tracercoll._set_mesh(newmesh)


        # Rebuild
        self.rebuild_global_mesh_from_list(rebuild=True)
        for m in self._interfacemeshes:
            m.rebuild_after_adapt()
            m.ensure_external_data()
        # print("REBUILD INTERFACE MESH",m.nelement())
        if len(self._interfacemeshes):
            if not self.is_quiet():
                print("REBUILDING GLOBAL MESH")
            self.rebuild_global_mesh()
        for m in self._meshtemplate_list:
            m._connect_opposite_elements(self._equation_system) 

        self.rebuild_global_mesh_from_list(rebuild=True)
        self.reapply_boundary_conditions()

        interpolators:Dict[str,"BaseMeshToMeshInterpolator"]={}
        # Apply the interpolation on each mesh: First on the boundaries and then down to the bulk mesh
        def perform_interpolation():
            for _, interp in interpolators.items(): 
                interp.interpolate() 


        num_adapt = self.max_refinement_level if num_adapt is None else num_adapt


        for name, newmesh in new_meshes.items():
            
            oldmesh = old_meshes[name]
            #oldmesh.prepare_interpolation() # This one will change the Lagrangian coordinates!
            interpolators[name]=interpolator(oldmesh,newmesh)
            oldmesh.get_eqtree()._before_mesh_to_mesh_interpolation(interpolators[name])

        if num_adapt > 0:
            no_need_to_reassign = False
            for s in range(num_adapt):
                perform_interpolation()
                if not self.is_quiet():
                    print("Remeshing adaption:", s, "of", num_adapt)
                nref, nunref = self._adapt()
                if nref == 0 and nunref == 0:
                    no_need_to_reassign = True
                    break
            if num_adapt > 0 and not (no_need_to_reassign):
                self.map_nodes_on_macro_elements()
                perform_interpolation()
        else:
            self.map_nodes_on_macro_elements()
            perform_interpolation()

        self.remove_macro_elements()

        self.actions_after_remeshing()
        for r in remeshers:
            r.actions_after_remeshing()
        self.invalidate_cached_mesh_data()



    def _get_time_of_state_file(self,fname:str):
        state=DumpFile(fname,False)
        state.string_data(lambda: self._dump_header, lambda s: state.assert_equal(s, self._dump_header))
        _version_str = state.string_data(lambda: self._dump_version, lambda s: state.assert_leq(s, self._dump_version))
        # Current time
        t=state.float_data(lambda: self.get_current_time(dimensional=True, as_float=True),lambda t: t)
        s = state.int_data(lambda: self._output_step, lambda s: s)
        state.close()
        return t,s

    # This function defines the state file, i.e. storing or reading all relevant information of the current status of the simulations
    def define_state_file(self, state:DumpFile,ignore_loading_eigendata:bool=False,ignore_continuation_data=False,additional_info={}):
        # Please do not modify the first part, it is required in that order for peeking the current time  in _get_time_of_state_file()
        # Header
        state.string_data(lambda: self._dump_header, lambda s: state.assert_equal(s, self._dump_header))
        _version_str = state.string_data(lambda: self._dump_version, lambda s: state.assert_leq(s, self._dump_version))

        # Current time
        state.float_data(lambda: self.get_current_time(dimensional=True, as_float=True),lambda t: self.set_current_time(t, dimensional=True, as_float=True))
        self._output_step = state.int_data(lambda: self._output_step, lambda s: s)

        # Continue section step
        self._continue_section_step_loaded=state.int_data(lambda: self._continue_section_step,lambda v:v)

        # From here on, you can in principle modify. Of course, old state files are incompatible once you add/remove anything here

        # Numpy array compression level
        compression=-100 if state.compression_level is None else state.compression_level
        state.compression_level=state.int_data(lambda : compression, lambda v:v)
        if state.compression_level==-100:
            state.compression_level=None
            
        # Mesh templates
        state.int_data(lambda : len(self._meshtemplate_list),lambda n : state.assert_equal(n,len(self._meshtemplate_list)))

        new_meshes:Dict[str,Union[MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d]] = {}
        old_meshes:Dict[str,Union[MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d]]= {}
        for _i,templ in enumerate(self._meshtemplate_list):
            old=templ.get_template()
            new=templ.define_state_file(state,additional_info=additional_info)
            if not state.save:
#                print("OLD VS NEW",old,new)
                if old!=new:
#                    print("OLD VS NEW2", old, new)
                    for n,om in self._meshdict.items():
                        if old.has_domain(n):
                            assert isinstance(om,(MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d))
                            old_meshes[n]=om
                            new_meshes[n]=MeshFromTemplate(self,new,n,om._eqtree,om)  

        if not state.save:
            for name, newmesh in new_meshes.items():
                oldmesh = old_meshes[name]
                self._meshdict[name] = newmesh
                assert oldmesh._codegen is not None
                oldmesh._codegen._mesh = newmesh 
                assert oldmesh._codegen._code is not None
                oldmesh._codegen._code._exchange_mesh(newmesh) 
#                print("REPLACING MESH ",name,"from",oldmesh,"to",newmesh)
                newmesh._construct_after_remesh() 
                for tree_depth in range(2):
                    newmesh._generate_interface_elements(tree_depth) 
            # Rebuild
            if len(new_meshes)>=0:
                self.rebuild_global_mesh_from_list(rebuild=True)
                for m in self._interfacemeshes:
                    m.rebuild_after_adapt()
                    m.ensure_external_data()
                # print("REBUILD INTERFACE MESH",m.nelement())
                if len(self._interfacemeshes):
                    if not self.is_quiet():
                        print("REBUILDING GLOBAL MESH")
                    self.rebuild_global_mesh()
                for m in self._meshtemplate_list:
                    m._connect_opposite_elements(self._equation_system) 

                self.rebuild_global_mesh_from_list(rebuild=True)
                self.reapply_boundary_conditions()



        # Time stepper dts
        time = self.timestepper.time_pt()
        ndt = state.int_data(lambda: time.ndt(), lambda ndt: state.assert_equal(ndt, time.ndt()))
        for dt in range(ndt):
            _dtval=state.float_data(lambda: time.dt(dt), lambda v: time.set_dt(dt, v))

        if not state.save:
            self.timestepper.set_weights()

        state.int_data(lambda: self.timestepper.get_num_unsteady_steps_done(),lambda t: self.timestepper.set_num_unsteady_steps_done(t))

        # Mesh list
        nummeshes = len(self._meshdict)
        nummeshes = state.int_data(lambda: nummeshes, lambda n: state.assert_equal(n, nummeshes)) #type:ignore
        mesh_name_list = list(sorted(list(self._meshdict.keys())))
        for nmesh in range(nummeshes):
            meshname = state.string_data(lambda: mesh_name_list[nmesh], lambda s: s)
            assert meshname in self._meshdict.keys()
            mesh = self._meshdict[meshname]
            assert not isinstance(mesh,InterfaceMesh)
            mesh.define_state_file(state,additional_info={})
        # Global params
        gpars = list(sorted(self.get_global_parameter_names()))
        numgpars = len(gpars)
        numgpars = state.int_data(lambda: numgpars, lambda n: state.assert_equal(n, numgpars)) #type:ignore
        for ngpar in range(numgpars):
            gparname = state.string_data(lambda: gpars[ngpar], lambda s: state.assert_equal(s, gpars[ngpar]))
            gp = self.get_global_parameter(gparname)
            gp.value = state.float_data(lambda: gp.value, lambda v: v)

        # Eigendata if desired
        write_eigen=1 if (self.eigen_data_in_states is not False) else 0
        has_eigendata=state.int_data(lambda : write_eigen,lambda n : n)
        if has_eigendata:
            if state.save:
                if self.eigen_data_in_states is True:
                    numeigen=len(self._last_eigenvalues)
                elif isinstance(self.eigen_data_in_states,int): #type:ignore
                    numeigen=min(self.eigen_data_in_states,len(self._last_eigenvalues))
            else:
                numeigen=0
            numeigen=state.int_data(lambda : numeigen,lambda n : n)
            has_azimuthal=1 if (self._last_eigenvalues_m is not None) else 0
            if numeigen>0:
                # Eigenvectors
                if not state.save:
                    evals=state.numpy_data(lambda  : self._last_eigenvalues,lambda e:e)
                    evects=state.numpy_data(lambda  : self._last_eigenvectors,lambda e:e)                
                    if not ignore_loading_eigendata:
                        self._last_eigenvalues=evals.copy()
                        self._last_eigenvectors=evects.copy()
                    has_azimuthal=state.int_data(lambda : has_azimuthal, lambda e :e)
                    if has_azimuthal:
                        ms=state.numpy_data(lambda  : self._last_eigenvalues_m,lambda e:e) #type:ignore
                        if not ignore_loading_eigendata:
                            self._last_eigenvalues_m=ms.copy()
                else:
                    state.numpy_data(lambda  : self._last_eigenvalues[:numeigen],lambda e:e)
                    state.numpy_data(lambda  : self._last_eigenvectors[:numeigen,:],lambda e:e)
                    if state.int_data(lambda : has_azimuthal, lambda e :e):
                        state.numpy_data(lambda  : self._last_eigenvalues_m[:numeigen],lambda e:e) #type:ignore
        #return
        write_conti=1 if (self.continuation_data_in_states is not False) else 0
        if state.save:
            dofderiv=self.get_arclength_dof_derivative_vector()
            if len(dofderiv)==0:
                write_conti=0
        else:
            dofderiv=[]
        has_contidata=state.int_data(lambda : write_conti,lambda n : n)
        if has_contidata:
            dofderiv=state.numpy_data(lambda  : dofderiv,lambda e:e)
            paramderiv=state.float_data(lambda  : self.get_arc_length_parameter_derivative(),lambda e:e)
            thetasqr=state.float_data(lambda  : self.get_arc_length_theta_sqr(),lambda e:e)
            if not state.save and not ignore_continuation_data:            
                self._set_dof_direction_arclength(dofderiv)
                self._set_arc_length_parameter_derivative(paramderiv)
                self._set_arc_length_theta_sqr(thetasqr)
        else:
            if not state.save:
                self.reset_arc_length_parameters()
            

            
        # Save the last BC settings. E.g. eigensolvers may have different values pinned. This is important for the eigen-vector data to match
        #self._last_bc_setting=state.string_data(lambda : self._last_bc_setting,lambda s:s)
                

        


    def save_state(self, fname:str,relative_to_output:bool=False)->None:
        if self.is_distributed():
            raise RuntimeError("Distributed save state")
        elif get_mpi_rank()>0:
            return

        if not self.is_quiet():
            print("Saving state ", fname)
        if relative_to_output:
            fname=os.path.join(self.get_output_directory(),fname)
        dump = DumpFile(fname, True,compression_level=self.states_compression_level)
        self.define_state_file(dump)
        dump.write_footer("EOF_pyoomph")
        dump.close()


    def load_state(self, fname:str,ignore_outstep:bool=False,relative_to_output:bool=False,ignore_eigendata:bool=False,ignore_continuation_data:bool=False,additional_info:Dict[Any,Any]={}):
        if not self.is_initialised():
            self.initialise()
        if self.is_distributed():
            raise RuntimeError("Distributed load state")
        if relative_to_output:
            fname=os.path.join(self.get_output_directory(),fname)

        _pyoomph.set_interpolate_new_interface_dofs(False) # We may not interpolate the additional dofs on newly constructed interface nodes
        self.invalidate_cached_mesh_data()
        dump = DumpFile(fname, False)
        good=dump.check_footer("EOF_pyoomph")
        if not good:
            raise RuntimeError("Unsupported state file: "+fname)
        for m in self._interfacemeshes:
            m.clear_before_adapt()
        oldoutstep=self._output_step
        self.define_state_file(dump,ignore_loading_eigendata=ignore_eigendata,ignore_continuation_data=ignore_continuation_data,additional_info=additional_info)
        self.invalidate_cached_mesh_data()
        if ignore_outstep:
            self._output_step=oldoutstep
        print("State file "+fname+" loaded")
        for m in self._interfacemeshes:
            m.clear_before_adapt()
        self.invalidate_cached_mesh_data()
        self.rebuild_global_mesh_from_list(rebuild=True)
        self.actions_after_adapt()
        self.setup_pinning()
        self.reapply_boundary_conditions()
        self.invalidate_cached_mesh_data()
        dump.close()

        self.actions_after_remeshing() # Must call this to inform e.g. the outputters, that the mesh has changed!
        
        self.invalidate_cached_mesh_data()
        if self._last_bc_setting=="eigen":
            self.actions_before_eigen_solve()
        elif self._last_bc_setting=="transient":
            self.actions_before_transient_solve()
        elif self._last_bc_setting=="stationary":
            self.actions_before_stationary_solve()
        _pyoomph.set_interpolate_new_interface_dofs(True) # Activate the interpolation again, good for spatial adaptivity
        return True

    def select_dofs(self) -> "_DofSelector":
        return _DofSelector(self)



############## DOF SELECTOR ###################
class _DofSelector:
    def __init__(self,problem:"Problem"):
        self._problem=problem
        self._all_unselected:Optional[bool]=None
        self._tree:Dict[str,Any]={}

    def __enter__(self):
        if not self._problem.is_initialised():
            self._problem.initialise()
        self._previous_dof_selector = self._problem._dof_selector
        self._problem._dof_selector = self 
        for ism in range(self._problem.nsub_mesh()):
            submesh = self._problem.mesh_pt(ism)
            if isinstance(submesh, (MeshFromTemplate1d,MeshFromTemplate2d,MeshFromTemplate3d,InterfaceMesh,ODEStorageMesh)):
                n=submesh.get_full_name()
                splt=n.split("/")
                node=self._tree
                for k in splt:
                    if not k in node.keys():
                        node[k]={}
                        node[k]["__parent__"]=node
                    node=node[k]
                fi=submesh.get_field_information()
                for fentry,space in fi.items():
                        node[fentry]=[space,None]
        return self

    def __exit__(self, exc_type, exc_val, exc_tb): #type:ignore
        # Set to the previous one
        self._problem._dof_selector=self._previous_dof_selector 


    def _traverse(self,n:Dict[str,Any],select:bool,onlydof:Optional[str]=None):
        for k,v in n.items():
            if k=="__parent__":
                continue
            if isinstance(v,list):
                if onlydof is not None:
                    if onlydof!=k:
                        continue
                n[k][1]=select # Unselect all
            elif isinstance(v,dict):
                self._traverse(n[k],select,onlydof=onlydof)

    def unselect_all(self):
        self._problem._dof_selector_used= "INVALID" 
        self._problem.invalidate_eigendata()        
        self._all_unselected=True
        self._traverse(self._tree,False)

    def select_all(self):
        self._problem._dof_selector_used= "INVALID" 
        self._problem.invalidate_eigendata()
        self._all_unselected=False
        self._traverse(self._tree,True)

    def _select_or_unselect(self,k:str,select:bool):
        splt = k.split("/")
        node = self._tree
        prev_node=None
        for k in splt:
            if k not in node.keys():
                raise RuntimeError("Cannot select or unselect " + k + " since it does not index a field or a mesh. " "Available fields on this mesh: "+str([nam for nam in node.keys() if nam!="__parent__"]))
            prev_node=node
            node = node[k]
        if isinstance(node, list):
            node[1] = select
            if prev_node is not None:
                self._traverse(prev_node, select,onlydof=k)
        elif isinstance(node, dict):
            self._traverse(node, select)

    # Selects meshes (e.g. "droplet") or degrees (e.g. "droplet/velocity_x"), both including interface meshes
    def select(self,*args:str):
        if self._all_unselected is None:
            self.unselect_all()
        self._problem._dof_selector_used = "INVALID" 
        self._problem.invalidate_eigendata()
        for k in args:
            self._select_or_unselect(k,True)

    def unselect(self,*args:str):
        if self._all_unselected is None:
            self.select_all()
        self._problem._dof_selector_used = "INVALID" 
        self._problem.invalidate_eigendata()
        for k in args:
            self._select_or_unselect(k,False)


    def _apply_on_domain(self,mesh:Optional[AnyMesh])->None:
        #print("APPLY ON DOMAIN",mesh)
        if mesh is None:
            return
        fn=mesh.get_full_name()
        splt = fn.split("/")
        #print(splt)
        node = self._tree
        for k in splt:
            node=node[k]
#        print(fn,"###########")
        selected:Set[str]=set()
        unselected:Set[str]=set()
        boundinds:Set[int]=set()
        for k,d in node.items():
            if isinstance(d,list):
                if d[1]:
                    selected.add(k)
        for bn in mesh.get_boundary_names():
            if node.get(bn,None) is not None:
                ind=mesh.get_boundary_index(bn)
                boundinds.add(ind)
        #print(selected,unselected,boundinds)
        mesh._pin_all_my_dofs(unselected,selected,boundinds)
